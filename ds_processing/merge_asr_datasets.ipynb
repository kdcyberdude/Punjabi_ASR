{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets to process\n",
    "# https://huggingface.co/datasets/aaparajit02/punjabi-asr / https://ai4bharat.iitm.ac.in/shrutilipi/ / # https://www.kaggle.com/datasets/warcoder/punjabi-speech-recognition\n",
    "# https://data.mendeley.com/datasets/sdbc8f5b77/2\n",
    "# https://figshare.com/articles/dataset/Google-synth_A_Synthesized_Punjabi_Speech_Dataset/23615607/1\n",
    "# https://figshare.com/articles/dataset/_strong_CMU-synth_A_synthesized_Punjabi_Speech_dataset_strong_/23606697/1\n",
    "# https://huggingface.co/datasets/google/fleurs\n",
    "# https://huggingface.co/datasets/mozilla-foundation/common_voice_16_1\n",
    "# https://ai4bharat.iitm.ac.in/indicvoices/\n",
    "# https://ai4bharat.iitm.ac.in/indicsuperb/\n",
    "\n",
    "# features: ['speaker_id', 'audio', 'text', 'gender', 'duration'],\n",
    "\n",
    "# CMU Synth and GoogleSynth is not good for TTS but good for ASR\n",
    "\n",
    "# Which columns to remove and retain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_from_disk, concatenate_datasets, Dataset, DatasetDict\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import pylab as plt\n",
    "from pydub import AudioSegment\n",
    "\n",
    "dir = '/mnt/data/Speech Dataset/processed_datasets/'\n",
    "# list dirs in dir\n",
    "dirs = os.listdir(dir)\n",
    "print(dirs)\n",
    "datasets = [load_from_disk(f'{dir}{d}') for d in dirs]\n",
    "\n",
    "for d, dir in zip(datasets, dirs):\n",
    "    print(dir)\n",
    "\n",
    "    for split in d:\n",
    "        source_column = [f'{dir}__{split}'] * len(d[split])\n",
    "        d[split] = d[split].add_column(\"source\", source_column)\n",
    "\n",
    "all_data_splits = []\n",
    "train_data_splits = []\n",
    "train_valid_data_splits = []\n",
    "test_data_splits = []\n",
    "valid_data_splits = []\n",
    "\n",
    "for d in datasets:\n",
    "    for split in d:\n",
    "        all_data_splits.append(d[split])\n",
    "        if split == 'train':\n",
    "            train_data_splits.append(d[split])\n",
    "        if split == 'train' or 'valid' in split:\n",
    "            train_valid_data_splits.append(d[split])\n",
    "        if split == 'test':\n",
    "            test_data_splits.append(d[split])\n",
    "        if 'valid' in split:\n",
    "            valid_data_splits.append(d[split])\n",
    "\n",
    "print(len(all_data_splits))\n",
    "print(len(train_data_splits))\n",
    "print(len(train_valid_data_splits))\n",
    "print(len(test_data_splits))\n",
    "print(len(valid_data_splits))\n",
    "\n",
    "ds_all = concatenate_datasets(all_data_splits)\n",
    "ds_train = concatenate_datasets(train_data_splits)\n",
    "ds_train_valid = concatenate_datasets(train_valid_data_splits)\n",
    "ds_test = concatenate_datasets(test_data_splits)\n",
    "ds_valid = concatenate_datasets(valid_data_splits)\n",
    "print(ds_all)\n",
    "print(ds_train)\n",
    "print(ds_train_valid)\n",
    "print(ds_test)\n",
    "print(ds_valid)\n",
    "\n",
    "# get indexes of audio files with duration >= 30s\n",
    "d = ds_all['duration']\n",
    "d_train = ds_train['duration']\n",
    "d_test = ds_test['duration']\n",
    "d_valid = ds_valid['duration']\n",
    "\n",
    "indexes = [i for i, x in enumerate(d) if x >= 30]\n",
    "indexes_train = [i for i, x in enumerate(d_train) if x >= 30]\n",
    "indexes_test = [i for i, x in enumerate(d_test) if x >= 30]\n",
    "indexes_valid = [i for i, x in enumerate(d_valid) if x >= 30]\n",
    "\n",
    "print(len(indexes))\n",
    "print(len(indexes_train))\n",
    "print(len(indexes_test))\n",
    "print(len(indexes_valid))\n",
    "\n",
    "\n",
    "indexes_all = list(range(len(ds_all)))\n",
    "indexes_all_train = list(range(len(ds_train)))\n",
    "indexes_all_test = list(range(len(ds_test)))\n",
    "indexes_all_valid = list(range(len(ds_valid)))\n",
    "\n",
    "indexes_all = [x for x in indexes_all if x not in indexes]\n",
    "indexes_all_train = [x for x in indexes_all_train if x not in indexes_train]\n",
    "indexes_all_test = [x for x in indexes_all_test if x not in indexes_test]\n",
    "indexes_all_valid = [x for x in indexes_all_valid if x not in indexes_valid]\n",
    "\n",
    "ds_all_f = ds_all.select(indexes_all)\n",
    "ds_train_f = ds_train.select(indexes_all_train)\n",
    "ds_test_f = ds_test.select(indexes_all_test)\n",
    "ds_valid_f = ds_valid.select(indexes_all_valid)\n",
    "\n",
    "d_tv = ds_train_valid['duration']\n",
    "indexes_tv = [i for i, x in enumerate(d_tv) if x >= 30]\n",
    "indexes_all_tv = list(range(len(ds_train_valid)))\n",
    "indexes_all_tv = [x for x in indexes_all_tv if x not in indexes_tv]\n",
    "ds_train_valid_f = ds_train_valid.select(indexes_all_tv)\n",
    "\n",
    "def get_split_duration(ds):\n",
    "    return sum(ds['duration']) / 3600\n",
    "\n",
    "print(f'{get_split_duration(ds_all_f)}, {get_split_duration(ds_train_f)}, {get_split_duration(ds_test_f)}, {get_split_duration(ds_valid_f)}, {get_split_duration(ds_train_valid_f)}')\n",
    "plt.hist(ds_all_f['duration'])\n",
    "plt.hist(ds_train_f['duration'])\n",
    "plt.hist(ds_train_valid_f['duration'])\n",
    "\n",
    "ds = DatasetDict({'train': ds_train_f, 'valid': ds_valid_f, 'test': ds_test_f})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train_f = ds_train_f.shuffle(seed=42)\n",
    "ds_valid_f = ds_valid_f.shuffle(seed=42)\n",
    "ds_test_f = ds_test_f.shuffle(seed=42)\n",
    "ds_train_f = ds_train_f.flatten_indices(num_proc=24,cache_file_name='/mnt/sea/tmp/ds_train_f2.cache', writer_batch_size = 32)\n",
    "ds_valid_f = ds_valid_f.flatten_indices(num_proc=24,cache_file_name='/mnt/sea/tmp/ds_valid_f2.cache', writer_batch_size = 32)\n",
    "ds_test_f = ds_test_f.flatten_indices(num_proc=24,cache_file_name='/mnt/sea/tmp/ds_test_f2.cache', writer_batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_final = DatasetDict({'train': ds_train_f, 'valid': ds_valid_f, 'test': ds_test_f})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_final.save_to_disk('/home/kd/Desktop/ds/Punjabi_ASR_DS', num_proc=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
