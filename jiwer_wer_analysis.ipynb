{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted 'buddy on' before reference index 0.\n",
      "Equal: 'what going' matches with hypothesis.\n",
      "Deleted 'on buddy' from reference where there are no corresponding hypothesis words.\n"
     ]
    }
   ],
   "source": [
    "from jiwer import compute_measures\n",
    "r = 'what going on buddy'\n",
    "p = \"boddy on what going\"\n",
    "compute_measures(r, p)\n",
    "\n",
    "from jiwer import AlignmentChunk\n",
    "\n",
    "def explain_operations(ops, reference_tokens, hypothesis_tokens):\n",
    "    # Explaining each operation in the ops list\n",
    "    for operation in ops:\n",
    "        for chunk in operation:\n",
    "            if chunk.type == 'insert':\n",
    "                inserted_words = \" \".join(hypothesis_tokens[chunk.hyp_start_idx:chunk.hyp_end_idx])\n",
    "                print(f\"Inserted '{inserted_words}' before reference index {chunk.ref_start_idx}.\")\n",
    "            elif chunk.type == 'delete':\n",
    "                deleted_words = \" \".join(reference_tokens[chunk.ref_start_idx:chunk.ref_end_idx])\n",
    "                print(f\"Deleted '{deleted_words}' from reference where there are no corresponding hypothesis words.\")\n",
    "            elif chunk.type == 'equal':\n",
    "                equal_words_ref = \" \".join(reference_tokens[chunk.ref_start_idx:chunk.ref_end_idx])\n",
    "                print(f\"Equal: '{equal_words_ref}' matches with hypothesis.\")\n",
    "            elif chunk.type == 'substitute':\n",
    "                substituted_words_ref = \" \".join(reference_tokens[chunk.ref_start_idx:chunk.ref_end_idx])\n",
    "                substituted_words_hyp = \" \".join(hypothesis_tokens[chunk.hyp_start_idx:chunk.hyp_end_idx])\n",
    "                print(f\"Substituted reference '{substituted_words_ref}' with hypothesis '{substituted_words_hyp}'.\")\n",
    "\n",
    "# Example usage:\n",
    "reference_tokens = [\"what\", \"going\", \"on\", \"buddy\"]\n",
    "hypothesis_tokens = [\"buddy\", \"on\", \"what\", \"going\"]\n",
    "\n",
    "ops_example = [\n",
    "    [AlignmentChunk(type='insert', ref_start_idx=0, ref_end_idx=0, hyp_start_idx=0, hyp_end_idx=2),\n",
    "     AlignmentChunk(type='equal', ref_start_idx=0, ref_end_idx=2, hyp_start_idx=2, hyp_end_idx=4),\n",
    "     AlignmentChunk(type='delete', ref_start_idx=2, ref_end_idx=4, hyp_start_idx=4, hyp_end_idx=4)]\n",
    "]\n",
    "\n",
    "explain_operations(ops_example, reference_tokens, hypothesis_tokens)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'wer': 0.75, 'mer': 0.75, 'wil': 0.9375, 'wip': 0.0625, 'hits': 2, 'substitutions': 6, 'deletions': 0, 'insertions': 0, 'ops': [[AlignmentChunk(type='substitute', ref_start_idx=0, ref_end_idx=2, hyp_start_idx=0, hyp_end_idx=2), AlignmentChunk(type='equal', ref_start_idx=2, ref_end_idx=4, hyp_start_idx=2, hyp_end_idx=4), AlignmentChunk(type='substitute', ref_start_idx=4, ref_end_idx=8, hyp_start_idx=4, hyp_end_idx=8)]], 'truth': [['honesty', 'is', 'the', 'best', 'policy', 'of', 'all', 'times']], 'hypothesis': [['honesy', 's', 'the', 'best', 'poliy', 'off', 'al', 'time']]}\n",
      "\n",
      "\n",
      "\n",
      "Substituted reference 'honesty is' with hypothesis 'honesy s'.\n",
      "Equal: 'the best' matches with hypothesis.\n",
      "Substituted reference 'policy of all times' with hypothesis 'poliy off al time'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1147348/265532448.py:10: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  wer_metric = load_metric(\"wer\")\n",
      "/home/kd/anaconda3/envs/ai4bharat/lib/python3.12/site-packages/datasets/load.py:759: FutureWarning: The repository for wer contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.1/metrics/wer/wer.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from jiwer import compute_measures\n",
    "r = 'honesty is the best policy of all times'\n",
    "p = \"honesy s the best poliy off al time\"\n",
    "x = compute_measures(r, p)\n",
    "print(x)\n",
    "print('\\n\\n')\n",
    "explain_operations(x['ops'], r.split(), p.split())\n",
    "\n",
    "from datasets import load_metric\n",
    "wer_metric = load_metric(\"wer\")\n",
    "\n",
    "wer_metric.compute(predictions=[\"what going on buddy?\"], references=[\"what\"])\n",
    "wer_metric.compute(predictions=[\"hello world\"], references=[\"hello world!\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai4bharat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
