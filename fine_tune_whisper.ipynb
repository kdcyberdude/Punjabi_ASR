{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "a2787582-554f-44ce-9f38-4180a5ed6b44",
      "metadata": {
        "id": "a2787582-554f-44ce-9f38-4180a5ed6b44"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/kd/Desktop/proj/apr/Punjabi_ASR/speech_utils.py:13: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
            "  wer_metric = load_metric(\"wer\")\n",
            "/home/kd/anaconda3/envs/ai4bharat/lib/python3.12/site-packages/datasets/load.py:759: FutureWarning: The repository for wer contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.1/metrics/wer/wer.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset, DatasetDict, Dataset, concatenate_datasets, IterableDataset, load_from_disk\n",
        "from transformers import Seq2SeqTrainer\n",
        "from transformers import Seq2SeqTrainingArguments\n",
        "import torch\n",
        "from transformers import WhisperForConditionalGeneration\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from typing import Any, Dict, List, Union\n",
        "import evaluate\n",
        "from transformers import WhisperProcessor\n",
        "from transformers import WhisperTokenizer\n",
        "from transformers import WhisperFeatureExtractor\n",
        "import pylab as plt\n",
        "import speech_utils as su\n",
        "\n",
        "metric = evaluate.load(\"wer\")\n",
        "chunk_length = 16\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "f1efa4a3",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f9b863c8ada04322ab162bf45821d457",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading dataset from disk:   0%|          | 0/67 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "965b92aadac44ca4ad1855ec548cc6ba",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading dataset from disk:   0%|          | 0/20 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset summary: \n",
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['audio', 'text', 'duration'],\n",
            "        num_rows: 167141\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['audio', 'text', 'duration'],\n",
            "        num_rows: 1486\n",
            "    })\n",
            "})\n",
            "train duration in hours: 289.02\n",
            "test duration in hours: 3.2\n",
            "Max duration: 29.346 seconds\n",
            "Min duration: 0.1380625 seconds\n",
            "Avg duration: 6.238641506475831 seconds\n",
            "\n",
            "Max text length: 474 characters\n",
            "Min text length: 0 characters\n",
            "Avg text length: 84.01642678811815 characters\n",
            "\n",
            "Train: 163829 (98.02%) | Removing 3312 samples\n",
            "Test: 1381 (92.93%) | Removing 105 samples\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "ds = load_from_disk(\"./datasets/Punjabi_ASR_2\")\n",
        "su.get_summary(ds)\n",
        "\n",
        "train_durations = ds['train']['duration']\n",
        "test_durations = ds['test']['duration']\n",
        "\n",
        "train_indexes = [i for i, duration in enumerate(train_durations) if duration < chunk_length]\n",
        "test_indexes = [i for i, duration in enumerate(test_durations) if duration < chunk_length]\n",
        "\n",
        "print(f\"Train: {len(train_indexes)} ({len(train_indexes)/len(train_durations)*100:.2f}%) | Removing {len(train_durations) - len(train_indexes)} samples\")\n",
        "print(f\"Test: {len(test_indexes)} ({len(test_indexes)/len(test_durations)*100:.2f}%) | Removing {len(test_durations) - len(test_indexes)} samples\")\n",
        "\n",
        "ds = DatasetDict({\n",
        "    'train': ds['train'].select(train_indexes),\n",
        "    'test': ds['test'].select(test_indexes)\n",
        "})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "802bede2",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/kd/anaconda3/envs/ai4bharat/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "model_name = 'openai/whisper-medium'\n",
        "feature_extractor = WhisperFeatureExtractor.from_pretrained(model_name, chunk_length=chunk_length)\n",
        "tokenizer = WhisperTokenizer.from_pretrained(model_name, language=\"Punjabi\", task=\"transcribe\")\n",
        "processor = WhisperProcessor(feature_extractor=feature_extractor, tokenizer=tokenizer)\n",
        "model = WhisperForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "model.generation_config.language = \"punjabi\"\n",
        "model.generation_config.task = \"transcribe\"\n",
        "\n",
        "model.generation_config.forced_decoder_ids = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "6525c478-8962-4394-a1c4-103c54cce170",
      "metadata": {
        "id": "6525c478-8962-4394-a1c4-103c54cce170"
      },
      "outputs": [],
      "source": [
        "def prepare_dataset(batch):\n",
        "    audio = batch[\"audio\"]\n",
        "    # compute log-Mel input features from input audio array\n",
        "    batch[\"input_features\"] = feature_extractor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_features[0]\n",
        "\n",
        "    # encode target text to label ids\n",
        "    batch[\"labels\"] = tokenizer(batch[\"text\"]).input_ids\n",
        "    return batch\n",
        "\n",
        "\n",
        "# for testing\n",
        "# ds = DatasetDict({\n",
        "#     'train': ds['train'].select(range(1000)),\n",
        "#     'test': ds['test'].select(range(1000))\n",
        "# })\n",
        "ds = ds.map(prepare_dataset, num_proc=1, cache_file_names={'train': \"/mnt/sea/temp/train-mid2.arrow\", 'test': \"/mnt/sea/temp/test-mid22.arrow\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "8326221e-ec13-4731-bb4e-51e5fc1486c5",
      "metadata": {
        "id": "8326221e-ec13-4731-bb4e-51e5fc1486c5"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "@dataclass\n",
        "class DataCollatorSpeechSeq2SeqWithPadding:\n",
        "    processor: Any\n",
        "    decoder_start_token_id: int\n",
        "\n",
        "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
        "        # split inputs and labels since they have to be of different lengths and need different padding methods\n",
        "        # first treat the audio inputs by simply returning torch tensors\n",
        "        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n",
        "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
        "\n",
        "        # get the tokenized label sequences\n",
        "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
        "        # pad the labels to max length\n",
        "        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n",
        "\n",
        "        # replace padding with -100 to ignore loss correctly\n",
        "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
        "\n",
        "        # if bos token is appended in previous tokenization step,\n",
        "        # cut bos token here as it's append later anyways\n",
        "        if (labels[:, 0] == self.decoder_start_token_id).all().cpu().item():\n",
        "            labels = labels[:, 1:]\n",
        "\n",
        "        batch[\"labels\"] = labels\n",
        "\n",
        "        return batch\n",
        "    \n",
        "data_collator = DataCollatorSpeechSeq2SeqWithPadding(\n",
        "    processor=processor,\n",
        "    decoder_start_token_id=model.config.decoder_start_token_id,\n",
        ")\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    pred_ids = pred.predictions\n",
        "    label_ids = pred.label_ids\n",
        "\n",
        "    # replace -100 with the pad_token_id\n",
        "    label_ids[label_ids == -100] = tokenizer.pad_token_id\n",
        "\n",
        "    # we do not want to group tokens when computing the metrics\n",
        "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
        "    label_str = tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
        "\n",
        "    wer = 100 * metric.compute(predictions=pred_str, references=label_str)\n",
        "\n",
        "    return {\"wer\": wer}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "0ae3e9af-97b7-4aa0-ae85-20b23b5bcb3a",
      "metadata": {
        "id": "0ae3e9af-97b7-4aa0-ae85-20b23b5bcb3a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "([50258, 50321, 50359, 50363, 156, 26741, 50257], 'à¨¹')"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"./checkpoints/whisper/whisper-medium-pa\",  \n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    gradient_accumulation_steps=2,  \n",
        "    learning_rate=1e-5,\n",
        "    num_train_epochs=14,\n",
        "    warmup_ratio=0.1,\n",
        "    dataloader_num_workers=4,\n",
        "    dataloader_prefetch_factor=8,\n",
        "    # max_steps=4000,\n",
        "    save_total_limit=4,\n",
        "    gradient_checkpointing=True,\n",
        "    bf16=True,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    run_name='whisper-medium-pa-1',\n",
        "    predict_with_generate=True,\n",
        "    # generation_max_length=225,\n",
        "    save_steps=300,\n",
        "    eval_steps=300,\n",
        "    logging_steps=10,\n",
        "    report_to=[\"tensorboard\", \"wandb\"],\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"wer\",\n",
        "    greater_is_better=False,\n",
        "    # push_to_hub=True,\n",
        ")\n",
        "tokenizer.encode(\"à¨¹\"), tokenizer.decode([156, 26741])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "77a8513c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Removing 471 samples from training set\n",
            "Removing 4 samples from test set\n",
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['audio', 'text', 'duration', 'input_features', 'labels'],\n",
            "        num_rows: 163358\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['audio', 'text', 'duration', 'input_features', 'labels'],\n",
            "        num_rows: 1377\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "train_labels_lengths = ds['train']['labels']\n",
        "test_labels_lengths = ds['test']['labels']\n",
        "\n",
        "train_labels_lengths = [len(i) for i in train_labels_lengths]\n",
        "test_labels_lengths = [len(i) for i in test_labels_lengths]\n",
        "\n",
        "train_selected_indexes = [i for i in range(len(train_labels_lengths)) if train_labels_lengths[i] < 446 and train_labels_lengths[i] > 6] # 5 tokens are special tokens added for each sequence\n",
        "test_selected_indexes = [i for i in range(len(test_labels_lengths)) if test_labels_lengths[i] < 446 and test_labels_lengths[i] > 6]\n",
        "\n",
        "print(f\"Removing {len(ds['train']) - len(train_selected_indexes)} samples from training set\")\n",
        "print(f\"Removing {len(ds['test']) - len(test_selected_indexes)} samples from test set\")\n",
        "\n",
        "train_ds = ds['train'].select(train_selected_indexes)\n",
        "test_ds = ds['test'].select(test_selected_indexes)\n",
        "\n",
        "ds = DatasetDict({\"train\": train_ds, \"test\": test_ds})\n",
        "print(ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "d546d7fe-0543-479a-b708-2ebabec19493",
      "metadata": {
        "id": "d546d7fe-0543-479a-b708-2ebabec19493"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/kd/anaconda3/envs/ai4bharat/lib/python3.12/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "trainer = Seq2SeqTrainer(\n",
        "    args=training_args,\n",
        "    model=model,\n",
        "    train_dataset=ds['train'],\n",
        "    eval_dataset=ds['test'],\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        "    tokenizer=processor.feature_extractor,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "-2zQwMfEOBJq",
      "metadata": {
        "id": "-2zQwMfEOBJq"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "processor.save_pretrained(training_args.output_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "ee8b7b8e-1c9a-4d77-9137-1778a629e6de",
      "metadata": {
        "id": "ee8b7b8e-1c9a-4d77-9137-1778a629e6de"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "There were missing keys in the checkpoint model loaded: ['proj_out.weight'].\n",
            "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkdcyberdude\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.0"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/kd/Desktop/proj/apr/Punjabi_ASR/wandb/run-20240518_125752-1gqpd7jx</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/kdcyberdude/huggingface/runs/1gqpd7jx' target=\"_blank\">whisper-medium-pa-1</a></strong> to <a href='https://wandb.ai/kdcyberdude/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/kdcyberdude/huggingface' target=\"_blank\">https://wandb.ai/kdcyberdude/huggingface</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/kdcyberdude/huggingface/runs/1gqpd7jx' target=\"_blank\">https://wandb.ai/kdcyberdude/huggingface/runs/1gqpd7jx</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fe07fc252a8f4885b98ec4696a5920a9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/71470 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/kd/anaconda3/envs/ai4bharat/lib/python3.12/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "`use_cache = True` is incompatible with gradient checkpointing. Setting `use_cache = False`...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.0119, 'grad_norm': 0.38743630051612854, 'learning_rate': 8.031341821743389e-06, 'epoch': 3.88}\n",
            "{'loss': 0.0122, 'grad_norm': 0.4175557792186737, 'learning_rate': 8.029787167887072e-06, 'epoch': 3.88}\n",
            "{'loss': 0.0113, 'grad_norm': 0.46016931533813477, 'learning_rate': 8.028232514030751e-06, 'epoch': 3.88}\n",
            "{'loss': 0.0115, 'grad_norm': 0.3341807425022125, 'learning_rate': 8.026677860174434e-06, 'epoch': 3.89}\n",
            "{'loss': 0.0129, 'grad_norm': 0.48281940817832947, 'learning_rate': 8.025123206318114e-06, 'epoch': 3.89}\n",
            "{'loss': 0.0113, 'grad_norm': 0.6110744476318359, 'learning_rate': 8.023568552461795e-06, 'epoch': 3.89}\n",
            "{'loss': 0.0104, 'grad_norm': 0.4603734612464905, 'learning_rate': 8.022013898605476e-06, 'epoch': 3.89}\n",
            "{'loss': 0.0115, 'grad_norm': 0.5257695913314819, 'learning_rate': 8.020459244749157e-06, 'epoch': 3.89}\n",
            "{'loss': 0.0119, 'grad_norm': 0.3990783095359802, 'learning_rate': 8.018904590892838e-06, 'epoch': 3.9}\n",
            "{'loss': 0.0132, 'grad_norm': 0.5538637042045593, 'learning_rate': 8.01734993703652e-06, 'epoch': 3.9}\n",
            "{'loss': 0.0124, 'grad_norm': 0.24334000051021576, 'learning_rate': 8.0157952831802e-06, 'epoch': 3.9}\n",
            "{'loss': 0.0114, 'grad_norm': 0.3862263262271881, 'learning_rate': 8.014240629323882e-06, 'epoch': 3.9}\n",
            "{'loss': 0.0123, 'grad_norm': 0.3671623766422272, 'learning_rate': 8.012685975467563e-06, 'epoch': 3.9}\n",
            "{'loss': 0.0109, 'grad_norm': 0.22863958775997162, 'learning_rate': 8.011131321611244e-06, 'epoch': 3.91}\n",
            "{'loss': 0.0097, 'grad_norm': 0.29134684801101685, 'learning_rate': 8.009576667754925e-06, 'epoch': 3.91}\n",
            "{'loss': 0.0108, 'grad_norm': 0.3227064311504364, 'learning_rate': 8.008022013898607e-06, 'epoch': 3.91}\n",
            "{'loss': 0.0096, 'grad_norm': 0.30858784914016724, 'learning_rate': 8.006467360042288e-06, 'epoch': 3.91}\n",
            "{'loss': 0.015, 'grad_norm': 0.5318952798843384, 'learning_rate': 8.004912706185969e-06, 'epoch': 3.91}\n",
            "{'loss': 0.0115, 'grad_norm': 0.4864647686481476, 'learning_rate': 8.00335805232965e-06, 'epoch': 3.92}\n",
            "{'loss': 0.012, 'grad_norm': 0.4233163893222809, 'learning_rate': 8.00180339847333e-06, 'epoch': 3.92}\n",
            "{'loss': 0.0102, 'grad_norm': 0.3297067880630493, 'learning_rate': 8.000248744617013e-06, 'epoch': 3.92}\n",
            "{'loss': 0.0142, 'grad_norm': 0.47534409165382385, 'learning_rate': 7.998694090760692e-06, 'epoch': 3.92}\n",
            "{'loss': 0.0107, 'grad_norm': 0.43995586037635803, 'learning_rate': 7.997139436904375e-06, 'epoch': 3.92}\n",
            "{'loss': 0.0138, 'grad_norm': 0.3806026577949524, 'learning_rate': 7.995584783048054e-06, 'epoch': 3.93}\n",
            "{'loss': 0.0108, 'grad_norm': 0.5836588740348816, 'learning_rate': 7.994030129191737e-06, 'epoch': 3.93}\n",
            "{'loss': 0.0112, 'grad_norm': 0.4032880961894989, 'learning_rate': 7.992475475335417e-06, 'epoch': 3.93}\n",
            "{'loss': 0.0137, 'grad_norm': 0.3406021296977997, 'learning_rate': 7.990920821479098e-06, 'epoch': 3.93}\n",
            "{'loss': 0.0117, 'grad_norm': 0.3308465778827667, 'learning_rate': 7.98936616762278e-06, 'epoch': 3.93}\n",
            "{'loss': 0.0115, 'grad_norm': 0.33339738845825195, 'learning_rate': 7.98781151376646e-06, 'epoch': 3.94}\n",
            "{'loss': 0.0124, 'grad_norm': 0.4146760106086731, 'learning_rate': 7.986256859910142e-06, 'epoch': 3.94}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8ae8930355ba43998acd7df00d1a91ea",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/87 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.10891363769769669, 'eval_wer': 22.70227808326787, 'eval_runtime': 706.461, 'eval_samples_per_second': 1.949, 'eval_steps_per_second': 0.123, 'epoch': 3.94}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/kd/anaconda3/envs/ai4bharat/lib/python3.12/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.0107, 'grad_norm': 0.2383657991886139, 'learning_rate': 7.984702206053823e-06, 'epoch': 3.94}\n",
            "{'loss': 0.0116, 'grad_norm': 0.34294381737709045, 'learning_rate': 7.983147552197504e-06, 'epoch': 3.94}\n",
            "{'loss': 0.0089, 'grad_norm': 0.3001566231250763, 'learning_rate': 7.981592898341185e-06, 'epoch': 3.94}\n",
            "{'loss': 0.0115, 'grad_norm': 0.35777974128723145, 'learning_rate': 7.980038244484866e-06, 'epoch': 3.95}\n",
            "{'loss': 0.012, 'grad_norm': 0.3759699761867523, 'learning_rate': 7.978483590628547e-06, 'epoch': 3.95}\n",
            "{'loss': 0.011, 'grad_norm': 0.4117361605167389, 'learning_rate': 7.976928936772229e-06, 'epoch': 3.95}\n",
            "{'loss': 0.0111, 'grad_norm': 0.30826735496520996, 'learning_rate': 7.97537428291591e-06, 'epoch': 3.95}\n",
            "{'loss': 0.0102, 'grad_norm': 0.34161171317100525, 'learning_rate': 7.973819629059591e-06, 'epoch': 3.95}\n",
            "{'loss': 0.0098, 'grad_norm': 0.5943753123283386, 'learning_rate': 7.972264975203272e-06, 'epoch': 3.95}\n",
            "{'loss': 0.0131, 'grad_norm': 0.38641247153282166, 'learning_rate': 7.970710321346953e-06, 'epoch': 3.96}\n",
            "{'loss': 0.0106, 'grad_norm': 0.31343990564346313, 'learning_rate': 7.969155667490633e-06, 'epoch': 3.96}\n",
            "{'loss': 0.0117, 'grad_norm': 0.424624502658844, 'learning_rate': 7.967601013634316e-06, 'epoch': 3.96}\n",
            "{'loss': 0.012, 'grad_norm': 0.40586984157562256, 'learning_rate': 7.966046359777995e-06, 'epoch': 3.96}\n",
            "{'loss': 0.0129, 'grad_norm': 0.35768505930900574, 'learning_rate': 7.964491705921678e-06, 'epoch': 3.96}\n",
            "{'loss': 0.0123, 'grad_norm': 0.511059045791626, 'learning_rate': 7.962937052065358e-06, 'epoch': 3.97}\n",
            "{'loss': 0.0105, 'grad_norm': 0.3313080370426178, 'learning_rate': 7.96138239820904e-06, 'epoch': 3.97}\n",
            "{'loss': 0.012, 'grad_norm': 0.3993280231952667, 'learning_rate': 7.95982774435272e-06, 'epoch': 3.97}\n",
            "{'loss': 0.0104, 'grad_norm': 0.3078857958316803, 'learning_rate': 7.958273090496401e-06, 'epoch': 3.97}\n",
            "{'loss': 0.0105, 'grad_norm': 0.435313880443573, 'learning_rate': 7.956718436640082e-06, 'epoch': 3.97}\n",
            "{'loss': 0.0103, 'grad_norm': 0.39225801825523376, 'learning_rate': 7.955163782783764e-06, 'epoch': 3.98}\n",
            "{'loss': 0.0113, 'grad_norm': 0.31845757365226746, 'learning_rate': 7.953609128927445e-06, 'epoch': 3.98}\n",
            "{'loss': 0.0125, 'grad_norm': 0.44090327620506287, 'learning_rate': 7.952054475071126e-06, 'epoch': 3.98}\n",
            "{'loss': 0.0118, 'grad_norm': 0.3828475773334503, 'learning_rate': 7.950499821214807e-06, 'epoch': 3.98}\n",
            "{'loss': 0.0097, 'grad_norm': 0.389447957277298, 'learning_rate': 7.948945167358488e-06, 'epoch': 3.98}\n",
            "{'loss': 0.011, 'grad_norm': 0.33577659726142883, 'learning_rate': 7.94739051350217e-06, 'epoch': 3.99}\n",
            "{'loss': 0.0109, 'grad_norm': 0.39822641015052795, 'learning_rate': 7.94583585964585e-06, 'epoch': 3.99}\n",
            "{'loss': 0.0105, 'grad_norm': 0.2838751971721649, 'learning_rate': 7.944281205789532e-06, 'epoch': 3.99}\n",
            "{'loss': 0.0088, 'grad_norm': 0.20842866599559784, 'learning_rate': 7.942726551933213e-06, 'epoch': 3.99}\n",
            "{'loss': 0.0121, 'grad_norm': 0.32127851247787476, 'learning_rate': 7.941171898076894e-06, 'epoch': 3.99}\n",
            "{'loss': 0.013, 'grad_norm': 0.4047505557537079, 'learning_rate': 7.939617244220575e-06, 'epoch': 4.0}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "095b7158d52e4c5c83cdc2819afe64dc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/87 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.10674350708723068, 'eval_wer': 22.314742079078293, 'eval_runtime': 696.7834, 'eval_samples_per_second': 1.976, 'eval_steps_per_second': 0.125, 'epoch': 4.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/kd/anaconda3/envs/ai4bharat/lib/python3.12/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.0135, 'grad_norm': 0.42230796813964844, 'learning_rate': 7.938062590364257e-06, 'epoch': 4.0}\n",
            "{'loss': 0.0104, 'grad_norm': 1.1114616394042969, 'learning_rate': 7.936507936507936e-06, 'epoch': 4.0}\n",
            "{'loss': 0.0061, 'grad_norm': 0.14996862411499023, 'learning_rate': 7.934953282651619e-06, 'epoch': 4.0}\n",
            "{'loss': 0.0068, 'grad_norm': 0.28733405470848083, 'learning_rate': 7.933398628795299e-06, 'epoch': 4.0}\n",
            "{'loss': 0.0081, 'grad_norm': 0.44585683941841125, 'learning_rate': 7.931843974938981e-06, 'epoch': 4.01}\n",
            "{'loss': 0.0054, 'grad_norm': 0.2728091776371002, 'learning_rate': 7.930289321082661e-06, 'epoch': 4.01}\n",
            "{'loss': 0.0067, 'grad_norm': 0.4981735646724701, 'learning_rate': 7.928734667226344e-06, 'epoch': 4.01}\n",
            "{'loss': 0.0072, 'grad_norm': 0.3703620433807373, 'learning_rate': 7.927180013370023e-06, 'epoch': 4.01}\n",
            "{'loss': 0.0073, 'grad_norm': 0.3951304256916046, 'learning_rate': 7.925625359513704e-06, 'epoch': 4.01}\n",
            "{'loss': 0.0073, 'grad_norm': 0.35336437821388245, 'learning_rate': 7.924070705657386e-06, 'epoch': 4.02}\n",
            "{'loss': 0.008, 'grad_norm': 0.3735587000846863, 'learning_rate': 7.922516051801067e-06, 'epoch': 4.02}\n",
            "{'loss': 0.0072, 'grad_norm': 0.503832221031189, 'learning_rate': 7.920961397944748e-06, 'epoch': 4.02}\n",
            "{'loss': 0.0068, 'grad_norm': 0.3288165330886841, 'learning_rate': 7.91940674408843e-06, 'epoch': 4.02}\n",
            "{'loss': 0.0073, 'grad_norm': 0.412814736366272, 'learning_rate': 7.91785209023211e-06, 'epoch': 4.02}\n",
            "{'loss': 0.0064, 'grad_norm': 0.2943098247051239, 'learning_rate': 7.916297436375792e-06, 'epoch': 4.03}\n",
            "{'loss': 0.0069, 'grad_norm': 0.2898705303668976, 'learning_rate': 7.914742782519473e-06, 'epoch': 4.03}\n",
            "{'loss': 0.0066, 'grad_norm': 0.40132954716682434, 'learning_rate': 7.913188128663154e-06, 'epoch': 4.03}\n",
            "{'loss': 0.007, 'grad_norm': 0.41398048400878906, 'learning_rate': 7.911633474806835e-06, 'epoch': 4.03}\n",
            "{'loss': 0.0086, 'grad_norm': 0.5307496190071106, 'learning_rate': 7.910078820950516e-06, 'epoch': 4.03}\n",
            "{'loss': 0.0065, 'grad_norm': 0.3214770555496216, 'learning_rate': 7.908524167094198e-06, 'epoch': 4.04}\n",
            "{'loss': 0.0075, 'grad_norm': 0.312551349401474, 'learning_rate': 7.906969513237879e-06, 'epoch': 4.04}\n",
            "{'loss': 0.0076, 'grad_norm': 0.31693869829177856, 'learning_rate': 7.90541485938156e-06, 'epoch': 4.04}\n",
            "{'loss': 0.0066, 'grad_norm': 0.46502426266670227, 'learning_rate': 7.90386020552524e-06, 'epoch': 4.04}\n",
            "{'loss': 0.0075, 'grad_norm': 0.31075674295425415, 'learning_rate': 7.902305551668922e-06, 'epoch': 4.04}\n",
            "{'loss': 0.0071, 'grad_norm': 0.16595272719860077, 'learning_rate': 7.900750897812602e-06, 'epoch': 4.05}\n",
            "{'loss': 0.0062, 'grad_norm': 0.7509132623672485, 'learning_rate': 7.899196243956285e-06, 'epoch': 4.05}\n",
            "{'loss': 0.0065, 'grad_norm': 0.3096759021282196, 'learning_rate': 7.897641590099964e-06, 'epoch': 4.05}\n",
            "{'loss': 0.0066, 'grad_norm': 0.4143679141998291, 'learning_rate': 7.896086936243647e-06, 'epoch': 4.05}\n",
            "{'loss': 0.0058, 'grad_norm': 0.4265250563621521, 'learning_rate': 7.894532282387327e-06, 'epoch': 4.05}\n",
            "{'loss': 0.0064, 'grad_norm': 0.2557665705680847, 'learning_rate': 7.892977628531008e-06, 'epoch': 4.05}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "25a815f0a4734b1f83fcc5958b897aaf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/87 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.12562678754329681, 'eval_wer': 22.697041110238285, 'eval_runtime': 700.7813, 'eval_samples_per_second': 1.965, 'eval_steps_per_second': 0.124, 'epoch': 4.05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/kd/anaconda3/envs/ai4bharat/lib/python3.12/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.0075, 'grad_norm': 0.33477112650871277, 'learning_rate': 7.891422974674689e-06, 'epoch': 4.06}\n",
            "{'loss': 0.0073, 'grad_norm': 0.30970972776412964, 'learning_rate': 7.88986832081837e-06, 'epoch': 4.06}\n",
            "{'loss': 0.0066, 'grad_norm': 0.29803937673568726, 'learning_rate': 7.888313666962051e-06, 'epoch': 4.06}\n",
            "{'loss': 0.0059, 'grad_norm': 0.4753675162792206, 'learning_rate': 7.886759013105732e-06, 'epoch': 4.06}\n",
            "{'loss': 0.0077, 'grad_norm': 0.33346354961395264, 'learning_rate': 7.885204359249414e-06, 'epoch': 4.06}\n",
            "{'loss': 0.007, 'grad_norm': 0.20188064873218536, 'learning_rate': 7.883649705393095e-06, 'epoch': 4.07}\n",
            "{'loss': 0.0063, 'grad_norm': 0.2760152518749237, 'learning_rate': 7.882095051536776e-06, 'epoch': 4.07}\n",
            "{'loss': 0.0077, 'grad_norm': 0.32079318165779114, 'learning_rate': 7.880540397680457e-06, 'epoch': 4.07}\n",
            "{'loss': 0.0075, 'grad_norm': 0.5267828106880188, 'learning_rate': 7.878985743824138e-06, 'epoch': 4.07}\n",
            "{'loss': 0.007, 'grad_norm': 0.4516128599643707, 'learning_rate': 7.87743108996782e-06, 'epoch': 4.07}\n",
            "{'loss': 0.0074, 'grad_norm': 0.5840098261833191, 'learning_rate': 7.8758764361115e-06, 'epoch': 4.08}\n",
            "{'loss': 0.0069, 'grad_norm': 0.6006278991699219, 'learning_rate': 7.874321782255182e-06, 'epoch': 4.08}\n",
            "{'loss': 0.0069, 'grad_norm': 0.5940771102905273, 'learning_rate': 7.872767128398863e-06, 'epoch': 4.08}\n",
            "{'loss': 0.0073, 'grad_norm': 0.74065101146698, 'learning_rate': 7.871212474542543e-06, 'epoch': 4.08}\n",
            "{'loss': 0.0088, 'grad_norm': 0.4816117584705353, 'learning_rate': 7.869657820686226e-06, 'epoch': 4.08}\n",
            "{'loss': 0.0079, 'grad_norm': 0.5287624597549438, 'learning_rate': 7.868103166829905e-06, 'epoch': 4.09}\n",
            "{'loss': 0.0069, 'grad_norm': 0.40653687715530396, 'learning_rate': 7.866548512973588e-06, 'epoch': 4.09}\n",
            "{'loss': 0.0064, 'grad_norm': 0.45623862743377686, 'learning_rate': 7.864993859117267e-06, 'epoch': 4.09}\n",
            "{'loss': 0.0079, 'grad_norm': 0.32858040928840637, 'learning_rate': 7.86343920526095e-06, 'epoch': 4.09}\n",
            "{'loss': 0.0055, 'grad_norm': 0.29921844601631165, 'learning_rate': 7.86188455140463e-06, 'epoch': 4.09}\n",
            "{'loss': 0.0064, 'grad_norm': 0.4978918731212616, 'learning_rate': 7.860329897548311e-06, 'epoch': 4.1}\n",
            "{'loss': 0.0081, 'grad_norm': 0.5238784551620483, 'learning_rate': 7.858775243691992e-06, 'epoch': 4.1}\n",
            "{'loss': 0.007, 'grad_norm': 0.3261943459510803, 'learning_rate': 7.857220589835673e-06, 'epoch': 4.1}\n",
            "{'loss': 0.0073, 'grad_norm': 0.288766473531723, 'learning_rate': 7.855665935979355e-06, 'epoch': 4.1}\n",
            "{'loss': 0.007, 'grad_norm': 0.3724490702152252, 'learning_rate': 7.854111282123036e-06, 'epoch': 4.1}\n",
            "{'loss': 0.0071, 'grad_norm': 0.6915225386619568, 'learning_rate': 7.852556628266717e-06, 'epoch': 4.11}\n",
            "{'loss': 0.0077, 'grad_norm': 0.2687883675098419, 'learning_rate': 7.851001974410398e-06, 'epoch': 4.11}\n",
            "{'loss': 0.0078, 'grad_norm': 0.3477354347705841, 'learning_rate': 7.84944732055408e-06, 'epoch': 4.11}\n",
            "{'loss': 0.0072, 'grad_norm': 0.3779115080833435, 'learning_rate': 7.84789266669776e-06, 'epoch': 4.11}\n",
            "{'loss': 0.0072, 'grad_norm': 0.4797916114330292, 'learning_rate': 7.846338012841442e-06, 'epoch': 4.11}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6afa934831d64e04ba910977af42f1f4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/87 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.12260511517524719, 'eval_wer': 22.498036135113907, 'eval_runtime': 697.6474, 'eval_samples_per_second': 1.974, 'eval_steps_per_second': 0.125, 'epoch': 4.11}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/kd/anaconda3/envs/ai4bharat/lib/python3.12/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.0077, 'grad_norm': 0.3062843680381775, 'learning_rate': 7.844783358985123e-06, 'epoch': 4.12}\n",
            "{'loss': 0.007, 'grad_norm': 0.21841658651828766, 'learning_rate': 7.843228705128804e-06, 'epoch': 4.12}\n",
            "{'loss': 0.0068, 'grad_norm': 0.33023154735565186, 'learning_rate': 7.841674051272485e-06, 'epoch': 4.12}\n",
            "{'loss': 0.0083, 'grad_norm': 0.39443719387054443, 'learning_rate': 7.840119397416166e-06, 'epoch': 4.12}\n",
            "{'loss': 0.0066, 'grad_norm': 0.3508816063404083, 'learning_rate': 7.838564743559846e-06, 'epoch': 4.12}\n",
            "{'loss': 0.0074, 'grad_norm': 0.28658327460289, 'learning_rate': 7.837010089703529e-06, 'epoch': 4.13}\n",
            "{'loss': 0.0075, 'grad_norm': 0.20117910206317902, 'learning_rate': 7.835455435847208e-06, 'epoch': 4.13}\n",
            "{'loss': 0.0068, 'grad_norm': 0.40406402945518494, 'learning_rate': 7.833900781990891e-06, 'epoch': 4.13}\n",
            "{'loss': 0.0078, 'grad_norm': 0.47076988220214844, 'learning_rate': 7.83234612813457e-06, 'epoch': 4.13}\n",
            "{'loss': 0.0073, 'grad_norm': 0.3414202928543091, 'learning_rate': 7.830791474278252e-06, 'epoch': 4.13}\n",
            "{'loss': 0.0074, 'grad_norm': 0.47675246000289917, 'learning_rate': 7.829236820421933e-06, 'epoch': 4.14}\n",
            "{'loss': 0.0093, 'grad_norm': 0.3907511532306671, 'learning_rate': 7.827682166565614e-06, 'epoch': 4.14}\n",
            "{'loss': 0.0073, 'grad_norm': 0.2805464565753937, 'learning_rate': 7.826127512709295e-06, 'epoch': 4.14}\n",
            "{'loss': 0.0083, 'grad_norm': 0.41759932041168213, 'learning_rate': 7.824572858852977e-06, 'epoch': 4.14}\n",
            "{'loss': 0.0075, 'grad_norm': 0.24942368268966675, 'learning_rate': 7.823018204996658e-06, 'epoch': 4.14}\n",
            "{'loss': 0.0081, 'grad_norm': 0.2870008051395416, 'learning_rate': 7.821463551140339e-06, 'epoch': 4.14}\n",
            "{'loss': 0.0065, 'grad_norm': 0.3072822093963623, 'learning_rate': 7.81990889728402e-06, 'epoch': 4.15}\n",
            "{'loss': 0.0079, 'grad_norm': 0.3993004560470581, 'learning_rate': 7.818354243427701e-06, 'epoch': 4.15}\n",
            "{'loss': 0.0073, 'grad_norm': 0.3005545735359192, 'learning_rate': 7.816799589571383e-06, 'epoch': 4.15}\n",
            "{'loss': 0.008, 'grad_norm': 0.46737396717071533, 'learning_rate': 7.815244935715064e-06, 'epoch': 4.15}\n",
            "{'loss': 0.0093, 'grad_norm': 0.3679599165916443, 'learning_rate': 7.813690281858745e-06, 'epoch': 4.15}\n",
            "{'loss': 0.0078, 'grad_norm': 0.2933448553085327, 'learning_rate': 7.812135628002426e-06, 'epoch': 4.16}\n",
            "{'loss': 0.0083, 'grad_norm': 0.39848482608795166, 'learning_rate': 7.810580974146107e-06, 'epoch': 4.16}\n",
            "{'loss': 0.0078, 'grad_norm': 0.34116509556770325, 'learning_rate': 7.809026320289787e-06, 'epoch': 4.16}\n",
            "{'loss': 0.0089, 'grad_norm': 0.22362710535526276, 'learning_rate': 7.80747166643347e-06, 'epoch': 4.16}\n",
            "{'loss': 0.007, 'grad_norm': 0.364099383354187, 'learning_rate': 7.80591701257715e-06, 'epoch': 4.16}\n",
            "{'loss': 0.0077, 'grad_norm': 0.3665865957736969, 'learning_rate': 7.804362358720832e-06, 'epoch': 4.17}\n",
            "{'loss': 0.007, 'grad_norm': 0.25227829813957214, 'learning_rate': 7.802807704864512e-06, 'epoch': 4.17}\n",
            "{'loss': 0.0066, 'grad_norm': 0.407931923866272, 'learning_rate': 7.801253051008194e-06, 'epoch': 4.17}\n",
            "{'loss': 0.0081, 'grad_norm': 0.2261248677968979, 'learning_rate': 7.799698397151874e-06, 'epoch': 4.17}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b144c7dabb83438eb0337fff48a03c6b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/87 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.1221691220998764, 'eval_wer': 23.22073841319717, 'eval_runtime': 708.4474, 'eval_samples_per_second': 1.944, 'eval_steps_per_second': 0.123, 'epoch': 4.17}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/kd/anaconda3/envs/ai4bharat/lib/python3.12/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.0078, 'grad_norm': 0.4292007386684418, 'learning_rate': 7.798143743295555e-06, 'epoch': 4.17}\n",
            "{'loss': 0.0067, 'grad_norm': 0.3009757995605469, 'learning_rate': 7.796589089439236e-06, 'epoch': 4.18}\n",
            "{'loss': 0.0083, 'grad_norm': 0.30004334449768066, 'learning_rate': 7.795034435582917e-06, 'epoch': 4.18}\n",
            "{'loss': 0.0062, 'grad_norm': 0.1941019743680954, 'learning_rate': 7.793479781726599e-06, 'epoch': 4.18}\n",
            "{'loss': 0.008, 'grad_norm': 0.6319449543952942, 'learning_rate': 7.79192512787028e-06, 'epoch': 4.18}\n",
            "{'loss': 0.0069, 'grad_norm': 0.22142314910888672, 'learning_rate': 7.790370474013961e-06, 'epoch': 4.18}\n",
            "{'loss': 0.0071, 'grad_norm': 0.2791775166988373, 'learning_rate': 7.788815820157642e-06, 'epoch': 4.19}\n",
            "{'loss': 0.0074, 'grad_norm': 0.4468894898891449, 'learning_rate': 7.787261166301323e-06, 'epoch': 4.19}\n",
            "{'loss': 0.0072, 'grad_norm': 0.5571324229240417, 'learning_rate': 7.785706512445005e-06, 'epoch': 4.19}\n",
            "{'loss': 0.0084, 'grad_norm': 0.38248515129089355, 'learning_rate': 7.784151858588686e-06, 'epoch': 4.19}\n",
            "{'loss': 0.0065, 'grad_norm': 0.42172396183013916, 'learning_rate': 7.782597204732367e-06, 'epoch': 4.19}\n",
            "{'loss': 0.0062, 'grad_norm': 0.38932350277900696, 'learning_rate': 7.781042550876048e-06, 'epoch': 4.2}\n",
            "{'loss': 0.0071, 'grad_norm': 0.33724573254585266, 'learning_rate': 7.77948789701973e-06, 'epoch': 4.2}\n",
            "{'loss': 0.0073, 'grad_norm': 0.4537532329559326, 'learning_rate': 7.77793324316341e-06, 'epoch': 4.2}\n",
            "{'loss': 0.008, 'grad_norm': 0.3279058337211609, 'learning_rate': 7.776378589307092e-06, 'epoch': 4.2}\n",
            "{'loss': 0.0077, 'grad_norm': 0.3316424489021301, 'learning_rate': 7.774823935450773e-06, 'epoch': 4.2}\n",
            "{'loss': 0.0074, 'grad_norm': 0.39353522658348083, 'learning_rate': 7.773269281594454e-06, 'epoch': 4.21}\n",
            "{'loss': 0.0079, 'grad_norm': 0.5288139581680298, 'learning_rate': 7.771714627738135e-06, 'epoch': 4.21}\n",
            "{'loss': 0.0081, 'grad_norm': 0.2643079161643982, 'learning_rate': 7.770159973881816e-06, 'epoch': 4.21}\n",
            "{'loss': 0.0086, 'grad_norm': 0.17279958724975586, 'learning_rate': 7.768605320025498e-06, 'epoch': 4.21}\n",
            "{'loss': 0.0077, 'grad_norm': 0.263415664434433, 'learning_rate': 7.767050666169179e-06, 'epoch': 4.21}\n",
            "{'loss': 0.0078, 'grad_norm': 0.4136461317539215, 'learning_rate': 7.765496012312858e-06, 'epoch': 4.22}\n",
            "{'loss': 0.0076, 'grad_norm': 0.26957279443740845, 'learning_rate': 7.763941358456541e-06, 'epoch': 4.22}\n",
            "{'loss': 0.0074, 'grad_norm': 0.25677207112312317, 'learning_rate': 7.76238670460022e-06, 'epoch': 4.22}\n",
            "{'loss': 0.0088, 'grad_norm': 0.4053366184234619, 'learning_rate': 7.760832050743904e-06, 'epoch': 4.22}\n",
            "{'loss': 0.0071, 'grad_norm': 0.36211109161376953, 'learning_rate': 7.759277396887583e-06, 'epoch': 4.22}\n",
            "{'loss': 0.0082, 'grad_norm': 0.8227075338363647, 'learning_rate': 7.757722743031266e-06, 'epoch': 4.23}\n",
            "{'loss': 0.0074, 'grad_norm': 0.27933424711227417, 'learning_rate': 7.756168089174945e-06, 'epoch': 4.23}\n",
            "{'loss': 0.0063, 'grad_norm': 0.37013986706733704, 'learning_rate': 7.754613435318627e-06, 'epoch': 4.23}\n",
            "{'loss': 0.0071, 'grad_norm': 0.35415270924568176, 'learning_rate': 7.753058781462308e-06, 'epoch': 4.23}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e511b86080f74f5b89373872d88eced3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/87 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.12731249630451202, 'eval_wer': 23.341188792877716, 'eval_runtime': 697.5161, 'eval_samples_per_second': 1.974, 'eval_steps_per_second': 0.125, 'epoch': 4.23}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/kd/anaconda3/envs/ai4bharat/lib/python3.12/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.0074, 'grad_norm': 0.3988161087036133, 'learning_rate': 7.751504127605989e-06, 'epoch': 4.23}\n",
            "{'loss': 0.0081, 'grad_norm': 0.2996123731136322, 'learning_rate': 7.74994947374967e-06, 'epoch': 4.24}\n",
            "{'loss': 0.007, 'grad_norm': 0.40906426310539246, 'learning_rate': 7.748394819893351e-06, 'epoch': 4.24}\n",
            "{'loss': 0.0077, 'grad_norm': 1.028990626335144, 'learning_rate': 7.746840166037033e-06, 'epoch': 4.24}\n",
            "{'loss': 0.0074, 'grad_norm': 0.29162266850471497, 'learning_rate': 7.745285512180714e-06, 'epoch': 4.24}\n",
            "{'loss': 0.0074, 'grad_norm': 0.6266626119613647, 'learning_rate': 7.743730858324395e-06, 'epoch': 4.24}\n",
            "{'loss': 0.0085, 'grad_norm': 0.46779268980026245, 'learning_rate': 7.742176204468076e-06, 'epoch': 4.24}\n",
            "{'loss': 0.0066, 'grad_norm': 0.4601791203022003, 'learning_rate': 7.740621550611757e-06, 'epoch': 4.25}\n",
            "{'loss': 0.0081, 'grad_norm': 0.3009733259677887, 'learning_rate': 7.739066896755439e-06, 'epoch': 4.25}\n",
            "{'loss': 0.0082, 'grad_norm': 0.3411141037940979, 'learning_rate': 7.73751224289912e-06, 'epoch': 4.25}\n",
            "{'loss': 0.0084, 'grad_norm': 0.4161670506000519, 'learning_rate': 7.735957589042801e-06, 'epoch': 4.25}\n",
            "{'loss': 0.0075, 'grad_norm': 0.5531220436096191, 'learning_rate': 7.734402935186482e-06, 'epoch': 4.25}\n",
            "{'loss': 0.0067, 'grad_norm': 0.3517250120639801, 'learning_rate': 7.732848281330162e-06, 'epoch': 4.26}\n",
            "{'loss': 0.0082, 'grad_norm': 0.5304453372955322, 'learning_rate': 7.731293627473844e-06, 'epoch': 4.26}\n",
            "{'loss': 0.0071, 'grad_norm': 0.4348171353340149, 'learning_rate': 7.729738973617524e-06, 'epoch': 4.26}\n",
            "{'loss': 0.0086, 'grad_norm': 0.32957911491394043, 'learning_rate': 7.728184319761207e-06, 'epoch': 4.26}\n",
            "{'loss': 0.0065, 'grad_norm': 0.36164405941963196, 'learning_rate': 7.726629665904886e-06, 'epoch': 4.26}\n",
            "{'loss': 0.0072, 'grad_norm': 0.48176515102386475, 'learning_rate': 7.72507501204857e-06, 'epoch': 4.27}\n",
            "{'loss': 0.0084, 'grad_norm': 0.729289710521698, 'learning_rate': 7.723520358192249e-06, 'epoch': 4.27}\n",
            "{'loss': 0.0072, 'grad_norm': 0.46496301889419556, 'learning_rate': 7.72196570433593e-06, 'epoch': 4.27}\n",
            "{'loss': 0.0071, 'grad_norm': 0.24282924830913544, 'learning_rate': 7.720411050479611e-06, 'epoch': 4.27}\n",
            "{'loss': 0.0071, 'grad_norm': 0.5204841494560242, 'learning_rate': 7.718856396623292e-06, 'epoch': 4.27}\n",
            "{'loss': 0.0073, 'grad_norm': 0.21768461167812347, 'learning_rate': 7.717301742766973e-06, 'epoch': 4.28}\n",
            "{'loss': 0.0088, 'grad_norm': 0.4496259391307831, 'learning_rate': 7.715747088910655e-06, 'epoch': 4.28}\n",
            "{'loss': 0.0086, 'grad_norm': 0.46831855177879333, 'learning_rate': 7.714192435054336e-06, 'epoch': 4.28}\n",
            "{'loss': 0.0071, 'grad_norm': 0.2828545570373535, 'learning_rate': 7.712637781198017e-06, 'epoch': 4.28}\n",
            "{'loss': 0.0073, 'grad_norm': 0.4639686644077301, 'learning_rate': 7.711083127341698e-06, 'epoch': 4.28}\n",
            "{'loss': 0.0063, 'grad_norm': 0.2584516406059265, 'learning_rate': 7.70952847348538e-06, 'epoch': 4.29}\n",
            "{'loss': 0.0067, 'grad_norm': 0.3252321481704712, 'learning_rate': 7.70797381962906e-06, 'epoch': 4.29}\n",
            "{'loss': 0.0069, 'grad_norm': 0.5121977925300598, 'learning_rate': 7.706419165772742e-06, 'epoch': 4.29}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a8666e1f80b542aa942b6c8362cce8e1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/87 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.12442176789045334, 'eval_wer': 22.775595705682118, 'eval_runtime': 705.3029, 'eval_samples_per_second': 1.952, 'eval_steps_per_second': 0.123, 'epoch': 4.29}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/kd/anaconda3/envs/ai4bharat/lib/python3.12/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.0084, 'grad_norm': 0.17786897718906403, 'learning_rate': 7.704864511916423e-06, 'epoch': 4.29}\n",
            "{'loss': 0.0081, 'grad_norm': 0.34209519624710083, 'learning_rate': 7.703309858060104e-06, 'epoch': 4.29}\n",
            "{'loss': 0.0068, 'grad_norm': 0.4049270749092102, 'learning_rate': 7.701755204203785e-06, 'epoch': 4.3}\n",
            "{'loss': 0.0087, 'grad_norm': 0.3505982756614685, 'learning_rate': 7.700200550347465e-06, 'epoch': 4.3}\n",
            "{'loss': 0.0073, 'grad_norm': 0.5591179728507996, 'learning_rate': 7.698645896491148e-06, 'epoch': 4.3}\n",
            "{'loss': 0.007, 'grad_norm': 0.2679585814476013, 'learning_rate': 7.697091242634827e-06, 'epoch': 4.3}\n",
            "{'loss': 0.0078, 'grad_norm': 0.32134321331977844, 'learning_rate': 7.69553658877851e-06, 'epoch': 4.3}\n",
            "{'loss': 0.0072, 'grad_norm': 0.45481589436531067, 'learning_rate': 7.69398193492219e-06, 'epoch': 4.31}\n",
            "{'loss': 0.008, 'grad_norm': 0.3187521994113922, 'learning_rate': 7.692427281065872e-06, 'epoch': 4.31}\n",
            "{'loss': 0.0068, 'grad_norm': 0.17456448078155518, 'learning_rate': 7.690872627209552e-06, 'epoch': 4.31}\n",
            "{'loss': 0.0091, 'grad_norm': 0.5780462026596069, 'learning_rate': 7.689317973353233e-06, 'epoch': 4.31}\n",
            "{'loss': 0.0084, 'grad_norm': 0.8146166801452637, 'learning_rate': 7.687763319496914e-06, 'epoch': 4.31}\n",
            "{'loss': 0.0084, 'grad_norm': 0.4135877192020416, 'learning_rate': 7.686208665640596e-06, 'epoch': 4.32}\n",
            "{'loss': 0.0081, 'grad_norm': 0.6436406373977661, 'learning_rate': 7.684654011784277e-06, 'epoch': 4.32}\n",
            "{'loss': 0.008, 'grad_norm': 0.33044543862342834, 'learning_rate': 7.683099357927958e-06, 'epoch': 4.32}\n",
            "{'loss': 0.0077, 'grad_norm': 0.3413294553756714, 'learning_rate': 7.681544704071639e-06, 'epoch': 4.32}\n",
            "{'loss': 0.0079, 'grad_norm': 0.3467933237552643, 'learning_rate': 7.67999005021532e-06, 'epoch': 4.32}\n",
            "{'loss': 0.0082, 'grad_norm': 0.5182610154151917, 'learning_rate': 7.678435396359001e-06, 'epoch': 4.33}\n",
            "{'loss': 0.0085, 'grad_norm': 0.339989572763443, 'learning_rate': 7.676880742502683e-06, 'epoch': 4.33}\n",
            "{'loss': 0.0084, 'grad_norm': 0.32357779145240784, 'learning_rate': 7.675326088646364e-06, 'epoch': 4.33}\n",
            "{'loss': 0.007, 'grad_norm': 0.5158474445343018, 'learning_rate': 7.673771434790045e-06, 'epoch': 4.33}\n",
            "{'loss': 0.0079, 'grad_norm': 0.7207872271537781, 'learning_rate': 7.672216780933726e-06, 'epoch': 4.33}\n",
            "{'loss': 0.0063, 'grad_norm': 0.2343338578939438, 'learning_rate': 7.670662127077407e-06, 'epoch': 4.33}\n",
            "{'loss': 0.0076, 'grad_norm': 0.2999209761619568, 'learning_rate': 7.669107473221089e-06, 'epoch': 4.34}\n",
            "{'loss': 0.0081, 'grad_norm': 0.265373557806015, 'learning_rate': 7.667552819364768e-06, 'epoch': 4.34}\n",
            "{'loss': 0.007, 'grad_norm': 0.3959471583366394, 'learning_rate': 7.665998165508451e-06, 'epoch': 4.34}\n",
            "{'loss': 0.0061, 'grad_norm': 0.4596749544143677, 'learning_rate': 7.66444351165213e-06, 'epoch': 4.34}\n",
            "{'loss': 0.0072, 'grad_norm': 0.44806936383247375, 'learning_rate': 7.662888857795813e-06, 'epoch': 4.34}\n",
            "{'loss': 0.0079, 'grad_norm': 0.4310755729675293, 'learning_rate': 7.661334203939493e-06, 'epoch': 4.35}\n",
            "{'loss': 0.0089, 'grad_norm': 0.41190341114997864, 'learning_rate': 7.659779550083176e-06, 'epoch': 4.35}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "be75eb4814324ee5acd12e49a6109558",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/87 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.12251722067594528, 'eval_wer': 23.210264467137996, 'eval_runtime': 709.1272, 'eval_samples_per_second': 1.942, 'eval_steps_per_second': 0.123, 'epoch': 4.35}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/kd/anaconda3/envs/ai4bharat/lib/python3.12/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.0064, 'grad_norm': 0.37123969197273254, 'learning_rate': 7.658224896226855e-06, 'epoch': 4.35}\n",
            "{'loss': 0.0074, 'grad_norm': 0.4788702130317688, 'learning_rate': 7.656670242370536e-06, 'epoch': 4.35}\n",
            "{'loss': 0.0088, 'grad_norm': 0.33951643109321594, 'learning_rate': 7.655115588514218e-06, 'epoch': 4.35}\n",
            "{'loss': 0.0076, 'grad_norm': 0.4811355471611023, 'learning_rate': 7.653560934657899e-06, 'epoch': 4.36}\n",
            "{'loss': 0.0083, 'grad_norm': 0.4059833884239197, 'learning_rate': 7.65200628080158e-06, 'epoch': 4.36}\n",
            "{'loss': 0.0078, 'grad_norm': 0.4551253318786621, 'learning_rate': 7.650451626945261e-06, 'epoch': 4.36}\n",
            "{'loss': 0.0072, 'grad_norm': 0.37230828404426575, 'learning_rate': 7.648896973088942e-06, 'epoch': 4.36}\n",
            "{'loss': 0.0073, 'grad_norm': 0.5031944513320923, 'learning_rate': 7.647342319232624e-06, 'epoch': 4.36}\n",
            "{'loss': 0.0071, 'grad_norm': 0.5793173313140869, 'learning_rate': 7.645787665376305e-06, 'epoch': 4.37}\n",
            "{'loss': 0.0073, 'grad_norm': 0.3457436263561249, 'learning_rate': 7.644233011519986e-06, 'epoch': 4.37}\n",
            "{'loss': 0.0071, 'grad_norm': 0.48537197709083557, 'learning_rate': 7.642678357663667e-06, 'epoch': 4.37}\n",
            "{'loss': 0.0069, 'grad_norm': 0.3303816616535187, 'learning_rate': 7.641123703807348e-06, 'epoch': 4.37}\n",
            "{'loss': 0.0079, 'grad_norm': 0.4231374263763428, 'learning_rate': 7.63956904995103e-06, 'epoch': 4.37}\n",
            "{'loss': 0.0069, 'grad_norm': 0.28522053360939026, 'learning_rate': 7.63801439609471e-06, 'epoch': 4.38}\n",
            "{'loss': 0.0084, 'grad_norm': 0.23440980911254883, 'learning_rate': 7.636459742238392e-06, 'epoch': 4.38}\n",
            "{'loss': 0.0088, 'grad_norm': 0.40833911299705505, 'learning_rate': 7.634905088382071e-06, 'epoch': 4.38}\n",
            "{'loss': 0.007, 'grad_norm': 0.3196483254432678, 'learning_rate': 7.633350434525754e-06, 'epoch': 4.38}\n",
            "{'loss': 0.0077, 'grad_norm': 0.38675305247306824, 'learning_rate': 7.631795780669434e-06, 'epoch': 4.38}\n",
            "{'loss': 0.0077, 'grad_norm': 0.28697535395622253, 'learning_rate': 7.630241126813117e-06, 'epoch': 4.39}\n",
            "{'loss': 0.0089, 'grad_norm': 0.4878828823566437, 'learning_rate': 7.628686472956797e-06, 'epoch': 4.39}\n",
            "{'loss': 0.0088, 'grad_norm': 0.5090154409408569, 'learning_rate': 7.627131819100478e-06, 'epoch': 4.39}\n",
            "{'loss': 0.0063, 'grad_norm': 0.3233989477157593, 'learning_rate': 7.625577165244159e-06, 'epoch': 4.39}\n",
            "{'loss': 0.0073, 'grad_norm': 0.42750900983810425, 'learning_rate': 7.62402251138784e-06, 'epoch': 4.39}\n",
            "{'loss': 0.0085, 'grad_norm': 0.6567176580429077, 'learning_rate': 7.622467857531522e-06, 'epoch': 4.4}\n",
            "{'loss': 0.0084, 'grad_norm': 0.6024075746536255, 'learning_rate': 7.620913203675202e-06, 'epoch': 4.4}\n",
            "{'loss': 0.0077, 'grad_norm': 0.244238018989563, 'learning_rate': 7.619358549818884e-06, 'epoch': 4.4}\n",
            "{'loss': 0.008, 'grad_norm': 0.28749093413352966, 'learning_rate': 7.617803895962564e-06, 'epoch': 4.4}\n",
            "{'loss': 0.0075, 'grad_norm': 0.4561093747615814, 'learning_rate': 7.6162492421062464e-06, 'epoch': 4.4}\n",
            "{'loss': 0.0082, 'grad_norm': 0.394969642162323, 'learning_rate': 7.614694588249927e-06, 'epoch': 4.41}\n",
            "{'loss': 0.0082, 'grad_norm': 0.31137850880622864, 'learning_rate': 7.613139934393607e-06, 'epoch': 4.41}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c702fa3373fb4003bb8fd9a028e01b38",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/87 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.12286850810050964, 'eval_wer': 23.22073841319717, 'eval_runtime': 708.331, 'eval_samples_per_second': 1.944, 'eval_steps_per_second': 0.123, 'epoch': 4.41}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/kd/anaconda3/envs/ai4bharat/lib/python3.12/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.008, 'grad_norm': 0.3735682964324951, 'learning_rate': 7.611585280537289e-06, 'epoch': 4.41}\n",
            "{'loss': 0.0072, 'grad_norm': 0.33851420879364014, 'learning_rate': 7.6100306266809695e-06, 'epoch': 4.41}\n",
            "{'loss': 0.0071, 'grad_norm': 0.4059317409992218, 'learning_rate': 7.6084759728246515e-06, 'epoch': 4.41}\n",
            "{'loss': 0.0071, 'grad_norm': 0.5341202616691589, 'learning_rate': 7.606921318968332e-06, 'epoch': 4.42}\n",
            "{'loss': 0.0085, 'grad_norm': 0.3004628121852875, 'learning_rate': 7.605366665112014e-06, 'epoch': 4.42}\n",
            "{'loss': 0.0068, 'grad_norm': 0.3991486132144928, 'learning_rate': 7.603812011255694e-06, 'epoch': 4.42}\n",
            "{'loss': 0.0067, 'grad_norm': 0.3079737424850464, 'learning_rate': 7.6022573573993754e-06, 'epoch': 4.42}\n",
            "{'loss': 0.0076, 'grad_norm': 0.21149086952209473, 'learning_rate': 7.600702703543057e-06, 'epoch': 4.42}\n",
            "{'loss': 0.0071, 'grad_norm': 0.2804263234138489, 'learning_rate': 7.599148049686738e-06, 'epoch': 4.43}\n",
            "{'loss': 0.0085, 'grad_norm': 0.35807573795318604, 'learning_rate': 7.597593395830419e-06, 'epoch': 4.43}\n",
            "{'loss': 0.0075, 'grad_norm': 0.4052245318889618, 'learning_rate': 7.5960387419741e-06, 'epoch': 4.43}\n",
            "{'loss': 0.0081, 'grad_norm': 0.8259935975074768, 'learning_rate': 7.594484088117781e-06, 'epoch': 4.43}\n",
            "{'loss': 0.007, 'grad_norm': 0.34269979596138, 'learning_rate': 7.5929294342614626e-06, 'epoch': 4.43}\n",
            "{'loss': 0.0086, 'grad_norm': 0.36658424139022827, 'learning_rate': 7.591374780405143e-06, 'epoch': 4.43}\n",
            "{'loss': 0.0079, 'grad_norm': 0.4667815566062927, 'learning_rate': 7.589820126548825e-06, 'epoch': 4.44}\n",
            "{'loss': 0.0072, 'grad_norm': 0.4548746943473816, 'learning_rate': 7.588265472692505e-06, 'epoch': 4.44}\n",
            "{'loss': 0.0092, 'grad_norm': 0.5687474012374878, 'learning_rate': 7.586710818836187e-06, 'epoch': 4.44}\n",
            "{'loss': 0.0085, 'grad_norm': 0.38386213779449463, 'learning_rate': 7.585156164979868e-06, 'epoch': 4.44}\n",
            "{'loss': 0.0068, 'grad_norm': 0.37642309069633484, 'learning_rate': 7.58360151112355e-06, 'epoch': 4.44}\n",
            "{'loss': 0.0078, 'grad_norm': 0.43764737248420715, 'learning_rate': 7.58204685726723e-06, 'epoch': 4.45}\n",
            "{'loss': 0.0067, 'grad_norm': 0.3185693919658661, 'learning_rate': 7.58049220341091e-06, 'epoch': 4.45}\n",
            "{'loss': 0.0078, 'grad_norm': 0.3288535177707672, 'learning_rate': 7.578937549554592e-06, 'epoch': 4.45}\n",
            "{'loss': 0.0071, 'grad_norm': 0.30058571696281433, 'learning_rate': 7.577382895698273e-06, 'epoch': 4.45}\n",
            "{'loss': 0.007, 'grad_norm': 0.3115540146827698, 'learning_rate': 7.575828241841955e-06, 'epoch': 4.45}\n",
            "{'loss': 0.0071, 'grad_norm': 0.4271378815174103, 'learning_rate': 7.574273587985635e-06, 'epoch': 4.46}\n",
            "{'loss': 0.0071, 'grad_norm': 0.2024490088224411, 'learning_rate': 7.572718934129317e-06, 'epoch': 4.46}\n",
            "{'loss': 0.0076, 'grad_norm': 0.1988462209701538, 'learning_rate': 7.5711642802729975e-06, 'epoch': 4.46}\n",
            "{'loss': 0.0085, 'grad_norm': 0.4890362620353699, 'learning_rate': 7.569609626416679e-06, 'epoch': 4.46}\n",
            "{'loss': 0.0064, 'grad_norm': 0.22911947965621948, 'learning_rate': 7.56805497256036e-06, 'epoch': 4.46}\n",
            "{'loss': 0.0092, 'grad_norm': 0.49267083406448364, 'learning_rate': 7.566500318704041e-06, 'epoch': 4.47}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ccaf5fb55c6b449c932a80f3169e4c91",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/87 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.11861395835876465, 'eval_wer': 23.05315527625033, 'eval_runtime': 717.733, 'eval_samples_per_second': 1.919, 'eval_steps_per_second': 0.121, 'epoch': 4.47}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/kd/anaconda3/envs/ai4bharat/lib/python3.12/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.0091, 'grad_norm': 0.5160797238349915, 'learning_rate': 7.564945664847722e-06, 'epoch': 4.47}\n",
            "{'loss': 0.0083, 'grad_norm': 0.4177514612674713, 'learning_rate': 7.5633910109914034e-06, 'epoch': 4.47}\n",
            "{'loss': 0.0084, 'grad_norm': 0.3147270977497101, 'learning_rate': 7.561836357135085e-06, 'epoch': 4.47}\n",
            "{'loss': 0.0074, 'grad_norm': 0.367737352848053, 'learning_rate': 7.560281703278766e-06, 'epoch': 4.47}\n",
            "{'loss': 0.0098, 'grad_norm': 0.44982802867889404, 'learning_rate': 7.558727049422446e-06, 'epoch': 4.48}\n",
            "{'loss': 0.0069, 'grad_norm': 0.3961979150772095, 'learning_rate': 7.557172395566128e-06, 'epoch': 4.48}\n",
            "{'loss': 0.0081, 'grad_norm': 0.25207453966140747, 'learning_rate': 7.5556177417098085e-06, 'epoch': 4.48}\n",
            "{'loss': 0.0084, 'grad_norm': 0.4324323236942291, 'learning_rate': 7.5540630878534906e-06, 'epoch': 4.48}\n",
            "{'loss': 0.0085, 'grad_norm': 0.416794091463089, 'learning_rate': 7.552508433997171e-06, 'epoch': 4.48}\n",
            "{'loss': 0.0071, 'grad_norm': 0.4484061002731323, 'learning_rate': 7.550953780140853e-06, 'epoch': 4.49}\n",
            "{'loss': 0.0086, 'grad_norm': 0.5778310298919678, 'learning_rate': 7.549399126284533e-06, 'epoch': 4.49}\n",
            "{'loss': 0.0084, 'grad_norm': 0.45726239681243896, 'learning_rate': 7.5478444724282145e-06, 'epoch': 4.49}\n",
            "{'loss': 0.0073, 'grad_norm': 0.35452139377593994, 'learning_rate': 7.546289818571896e-06, 'epoch': 4.49}\n",
            "{'loss': 0.0084, 'grad_norm': 0.3754384219646454, 'learning_rate': 7.544735164715577e-06, 'epoch': 4.49}\n",
            "{'loss': 0.0066, 'grad_norm': 0.26305246353149414, 'learning_rate': 7.543180510859258e-06, 'epoch': 4.5}\n",
            "{'loss': 0.0072, 'grad_norm': 0.3385314643383026, 'learning_rate': 7.541625857002939e-06, 'epoch': 4.5}\n",
            "{'loss': 0.0081, 'grad_norm': 0.4061884582042694, 'learning_rate': 7.54007120314662e-06, 'epoch': 4.5}\n",
            "{'loss': 0.0089, 'grad_norm': 0.299337774515152, 'learning_rate': 7.538516549290302e-06, 'epoch': 4.5}\n",
            "{'loss': 0.0086, 'grad_norm': 0.39764025807380676, 'learning_rate': 7.536961895433982e-06, 'epoch': 4.5}\n",
            "{'loss': 0.0074, 'grad_norm': 0.22427316009998322, 'learning_rate': 7.535407241577664e-06, 'epoch': 4.51}\n",
            "{'loss': 0.0064, 'grad_norm': 0.48360884189605713, 'learning_rate': 7.533852587721344e-06, 'epoch': 4.51}\n",
            "{'loss': 0.0073, 'grad_norm': 0.3478868007659912, 'learning_rate': 7.532297933865026e-06, 'epoch': 4.51}\n",
            "{'loss': 0.0068, 'grad_norm': 0.34437131881713867, 'learning_rate': 7.530743280008707e-06, 'epoch': 4.51}\n",
            "{'loss': 0.0059, 'grad_norm': 0.3887048065662384, 'learning_rate': 7.529188626152389e-06, 'epoch': 4.51}\n",
            "{'loss': 0.0073, 'grad_norm': 0.6024596095085144, 'learning_rate': 7.527633972296069e-06, 'epoch': 4.52}\n",
            "{'loss': 0.0077, 'grad_norm': 0.3604533076286316, 'learning_rate': 7.526079318439749e-06, 'epoch': 4.52}\n",
            "{'loss': 0.0082, 'grad_norm': 0.5801069736480713, 'learning_rate': 7.5245246645834314e-06, 'epoch': 4.52}\n",
            "{'loss': 0.0082, 'grad_norm': 0.49501049518585205, 'learning_rate': 7.522970010727112e-06, 'epoch': 4.52}\n",
            "{'loss': 0.0068, 'grad_norm': 0.2727099657058716, 'learning_rate': 7.521415356870794e-06, 'epoch': 4.52}\n",
            "{'loss': 0.0076, 'grad_norm': 0.6250051259994507, 'learning_rate': 7.519860703014474e-06, 'epoch': 4.52}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "65f0621d30b1455bbf5052890fb5ddb6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/87 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.1228480264544487, 'eval_wer': 22.822728462948415, 'eval_runtime': 708.483, 'eval_samples_per_second': 1.944, 'eval_steps_per_second': 0.123, 'epoch': 4.52}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/kd/anaconda3/envs/ai4bharat/lib/python3.12/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.0073, 'grad_norm': 0.37069740891456604, 'learning_rate': 7.518306049158156e-06, 'epoch': 4.53}\n",
            "{'loss': 0.0074, 'grad_norm': 0.24638813734054565, 'learning_rate': 7.5167513953018365e-06, 'epoch': 4.53}\n",
            "{'loss': 0.0088, 'grad_norm': 0.40225258469581604, 'learning_rate': 7.515196741445518e-06, 'epoch': 4.53}\n",
            "{'loss': 0.0076, 'grad_norm': 0.24567873775959015, 'learning_rate': 7.513642087589199e-06, 'epoch': 4.53}\n",
            "{'loss': 0.0075, 'grad_norm': 0.42212262749671936, 'learning_rate': 7.51208743373288e-06, 'epoch': 4.53}\n",
            "{'loss': 0.0066, 'grad_norm': 0.19507452845573425, 'learning_rate': 7.510532779876561e-06, 'epoch': 4.54}\n",
            "{'loss': 0.0096, 'grad_norm': 0.6314536929130554, 'learning_rate': 7.5089781260202425e-06, 'epoch': 4.54}\n",
            "{'loss': 0.0072, 'grad_norm': 0.3783457577228546, 'learning_rate': 7.507423472163924e-06, 'epoch': 4.54}\n",
            "{'loss': 0.0093, 'grad_norm': 0.4484367370605469, 'learning_rate': 7.505868818307605e-06, 'epoch': 4.54}\n",
            "{'loss': 0.0081, 'grad_norm': 0.3243762254714966, 'learning_rate': 7.504314164451285e-06, 'epoch': 4.54}\n",
            "{'loss': 0.0074, 'grad_norm': 0.40223050117492676, 'learning_rate': 7.502759510594967e-06, 'epoch': 4.55}\n",
            "{'loss': 0.0087, 'grad_norm': 0.2779954969882965, 'learning_rate': 7.5012048567386476e-06, 'epoch': 4.55}\n",
            "{'loss': 0.0069, 'grad_norm': 0.3080447018146515, 'learning_rate': 7.49965020288233e-06, 'epoch': 4.55}\n",
            "{'loss': 0.0077, 'grad_norm': 0.3459773063659668, 'learning_rate': 7.49809554902601e-06, 'epoch': 4.55}\n",
            "{'loss': 0.0077, 'grad_norm': 0.39747369289398193, 'learning_rate': 7.496540895169692e-06, 'epoch': 4.55}\n",
            "{'loss': 0.007, 'grad_norm': 0.326861709356308, 'learning_rate': 7.494986241313372e-06, 'epoch': 4.56}\n",
            "{'loss': 0.0076, 'grad_norm': 0.2803618311882019, 'learning_rate': 7.493431587457053e-06, 'epoch': 4.56}\n",
            "{'loss': 0.0083, 'grad_norm': 0.5721489191055298, 'learning_rate': 7.491876933600735e-06, 'epoch': 4.56}\n",
            "{'loss': 0.0081, 'grad_norm': 0.4448128342628479, 'learning_rate': 7.490322279744415e-06, 'epoch': 4.56}\n",
            "{'loss': 0.0088, 'grad_norm': 0.5294440388679504, 'learning_rate': 7.488767625888097e-06, 'epoch': 4.56}\n",
            "{'loss': 0.0086, 'grad_norm': 0.4331073462963104, 'learning_rate': 7.487212972031777e-06, 'epoch': 4.57}\n",
            "{'loss': 0.0081, 'grad_norm': 0.2592555582523346, 'learning_rate': 7.485658318175459e-06, 'epoch': 4.57}\n",
            "{'loss': 0.0094, 'grad_norm': 0.41173064708709717, 'learning_rate': 7.48410366431914e-06, 'epoch': 4.57}\n",
            "{'loss': 0.0075, 'grad_norm': 0.3204649090766907, 'learning_rate': 7.482549010462821e-06, 'epoch': 4.57}\n",
            "{'loss': 0.0073, 'grad_norm': 0.32563185691833496, 'learning_rate': 7.480994356606502e-06, 'epoch': 4.57}\n",
            "{'loss': 0.0075, 'grad_norm': 0.6161068081855774, 'learning_rate': 7.479439702750183e-06, 'epoch': 4.58}\n",
            "{'loss': 0.0069, 'grad_norm': 0.2970285713672638, 'learning_rate': 7.4778850488938645e-06, 'epoch': 4.58}\n",
            "{'loss': 0.0076, 'grad_norm': 0.3433774411678314, 'learning_rate': 7.476330395037546e-06, 'epoch': 4.58}\n",
            "{'loss': 0.0064, 'grad_norm': 0.37015479803085327, 'learning_rate': 7.474775741181226e-06, 'epoch': 4.58}\n",
            "{'loss': 0.0078, 'grad_norm': 0.36355748772621155, 'learning_rate': 7.473221087324908e-06, 'epoch': 4.58}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8212399e927442a5a93b00c00ee66578",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/87 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.12612658739089966, 'eval_wer': 23.43021733438073, 'eval_runtime': 715.7219, 'eval_samples_per_second': 1.924, 'eval_steps_per_second': 0.122, 'epoch': 4.58}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/kd/anaconda3/envs/ai4bharat/lib/python3.12/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.0077, 'grad_norm': 0.4543229341506958, 'learning_rate': 7.4716664334685884e-06, 'epoch': 4.59}\n",
            "{'loss': 0.0077, 'grad_norm': 0.6675607562065125, 'learning_rate': 7.4701117796122705e-06, 'epoch': 4.59}\n",
            "{'loss': 0.0067, 'grad_norm': 0.3440577983856201, 'learning_rate': 7.468557125755951e-06, 'epoch': 4.59}\n",
            "{'loss': 0.0077, 'grad_norm': 0.41200220584869385, 'learning_rate': 7.467002471899633e-06, 'epoch': 4.59}\n",
            "{'loss': 0.0077, 'grad_norm': 0.3147966265678406, 'learning_rate': 7.465447818043313e-06, 'epoch': 4.59}\n",
            "{'loss': 0.008, 'grad_norm': 0.3047066926956177, 'learning_rate': 7.4638931641869935e-06, 'epoch': 4.6}\n",
            "{'loss': 0.0089, 'grad_norm': 0.21369583904743195, 'learning_rate': 7.4623385103306756e-06, 'epoch': 4.6}\n",
            "{'loss': 0.0078, 'grad_norm': 0.4995158016681671, 'learning_rate': 7.460783856474356e-06, 'epoch': 4.6}\n",
            "{'loss': 0.0076, 'grad_norm': 0.37912261486053467, 'learning_rate': 7.459229202618038e-06, 'epoch': 4.6}\n",
            "{'loss': 0.0079, 'grad_norm': 0.4223187267780304, 'learning_rate': 7.457674548761718e-06, 'epoch': 4.6}\n",
            "{'loss': 0.008, 'grad_norm': 0.6193392276763916, 'learning_rate': 7.4561198949054e-06, 'epoch': 4.61}\n",
            "{'loss': 0.0081, 'grad_norm': 0.5363755226135254, 'learning_rate': 7.454565241049081e-06, 'epoch': 4.61}\n",
            "{'loss': 0.0074, 'grad_norm': 0.27112406492233276, 'learning_rate': 7.453010587192762e-06, 'epoch': 4.61}\n",
            "{'loss': 0.0085, 'grad_norm': 0.1846626251935959, 'learning_rate': 7.451455933336443e-06, 'epoch': 4.61}\n",
            "{'loss': 0.0091, 'grad_norm': 0.2498672604560852, 'learning_rate': 7.449901279480124e-06, 'epoch': 4.61}\n",
            "{'loss': 0.0077, 'grad_norm': 0.30782055854797363, 'learning_rate': 7.448346625623805e-06, 'epoch': 4.62}\n",
            "{'loss': 0.0079, 'grad_norm': 0.3148764371871948, 'learning_rate': 7.446791971767487e-06, 'epoch': 4.62}\n",
            "{'loss': 0.008, 'grad_norm': 0.28611254692077637, 'learning_rate': 7.445237317911168e-06, 'epoch': 4.62}\n",
            "{'loss': 0.0081, 'grad_norm': 0.2871836721897125, 'learning_rate': 7.443682664054849e-06, 'epoch': 4.62}\n",
            "{'loss': 0.0092, 'grad_norm': 0.46109819412231445, 'learning_rate': 7.442128010198529e-06, 'epoch': 4.62}\n",
            "{'loss': 0.0078, 'grad_norm': 0.3229760527610779, 'learning_rate': 7.440573356342211e-06, 'epoch': 4.62}\n",
            "{'loss': 0.0074, 'grad_norm': 0.31343862414360046, 'learning_rate': 7.439018702485892e-06, 'epoch': 4.63}\n",
            "{'loss': 0.008, 'grad_norm': 0.4713229835033417, 'learning_rate': 7.437464048629574e-06, 'epoch': 4.63}\n",
            "{'loss': 0.0081, 'grad_norm': 0.46788737177848816, 'learning_rate': 7.435909394773254e-06, 'epoch': 4.63}\n",
            "{'loss': 0.0083, 'grad_norm': 0.35265493392944336, 'learning_rate': 7.434354740916936e-06, 'epoch': 4.63}\n",
            "{'loss': 0.0084, 'grad_norm': 0.39302486181259155, 'learning_rate': 7.4328000870606164e-06, 'epoch': 4.63}\n",
            "{'loss': 0.0103, 'grad_norm': 0.2026023119688034, 'learning_rate': 7.431245433204297e-06, 'epoch': 4.64}\n",
            "{'loss': 0.0088, 'grad_norm': 0.5753708481788635, 'learning_rate': 7.429690779347979e-06, 'epoch': 4.64}\n",
            "{'loss': 0.0088, 'grad_norm': 0.6310943961143494, 'learning_rate': 7.428136125491659e-06, 'epoch': 4.64}\n",
            "{'loss': 0.0081, 'grad_norm': 0.4031370282173157, 'learning_rate': 7.426581471635341e-06, 'epoch': 4.64}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7f46392611664ea798b8f8dbfa04f03c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/87 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.12146631628274918, 'eval_wer': 22.974600680806496, 'eval_runtime': 714.9137, 'eval_samples_per_second': 1.926, 'eval_steps_per_second': 0.122, 'epoch': 4.64}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/kd/anaconda3/envs/ai4bharat/lib/python3.12/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.0084, 'grad_norm': 0.3925301134586334, 'learning_rate': 7.4250268177790215e-06, 'epoch': 4.64}\n",
            "{'loss': 0.0082, 'grad_norm': 0.35659992694854736, 'learning_rate': 7.4234721639227036e-06, 'epoch': 4.65}\n",
            "{'loss': 0.0087, 'grad_norm': 0.520175576210022, 'learning_rate': 7.421917510066384e-06, 'epoch': 4.65}\n",
            "{'loss': 0.0075, 'grad_norm': 0.26617202162742615, 'learning_rate': 7.420362856210065e-06, 'epoch': 4.65}\n",
            "{'loss': 0.0086, 'grad_norm': 0.43561798334121704, 'learning_rate': 7.418808202353746e-06, 'epoch': 4.65}\n",
            "{'loss': 0.007, 'grad_norm': 0.28076595067977905, 'learning_rate': 7.4172535484974275e-06, 'epoch': 4.65}\n",
            "{'loss': 0.008, 'grad_norm': 0.3488987386226654, 'learning_rate': 7.415698894641109e-06, 'epoch': 4.66}\n",
            "{'loss': 0.0072, 'grad_norm': 0.460079163312912, 'learning_rate': 7.41414424078479e-06, 'epoch': 4.66}\n",
            "{'loss': 0.0082, 'grad_norm': 0.3516600728034973, 'learning_rate': 7.412589586928471e-06, 'epoch': 4.66}\n",
            "{'loss': 0.008, 'grad_norm': 0.4620111286640167, 'learning_rate': 7.411034933072152e-06, 'epoch': 4.66}\n",
            "{'loss': 0.0085, 'grad_norm': 0.29564368724823, 'learning_rate': 7.4094802792158326e-06, 'epoch': 4.66}\n",
            "{'loss': 0.0068, 'grad_norm': 0.2415839284658432, 'learning_rate': 7.407925625359515e-06, 'epoch': 4.67}\n",
            "{'loss': 0.0072, 'grad_norm': 0.30883148312568665, 'learning_rate': 7.406370971503195e-06, 'epoch': 4.67}\n",
            "{'loss': 0.008, 'grad_norm': 0.4856736660003662, 'learning_rate': 7.404816317646877e-06, 'epoch': 4.67}\n",
            "{'loss': 0.0071, 'grad_norm': 0.3007296621799469, 'learning_rate': 7.403261663790557e-06, 'epoch': 4.67}\n",
            "{'loss': 0.0082, 'grad_norm': 0.26632630825042725, 'learning_rate': 7.401707009934239e-06, 'epoch': 4.67}\n",
            "{'loss': 0.0075, 'grad_norm': 0.339508980512619, 'learning_rate': 7.40015235607792e-06, 'epoch': 4.68}\n",
            "{'loss': 0.0074, 'grad_norm': 0.47216352820396423, 'learning_rate': 7.3985977022216e-06, 'epoch': 4.68}\n",
            "{'loss': 0.0087, 'grad_norm': 0.530048668384552, 'learning_rate': 7.397043048365282e-06, 'epoch': 4.68}\n",
            "{'loss': 0.0071, 'grad_norm': 0.40064767003059387, 'learning_rate': 7.395488394508963e-06, 'epoch': 4.68}\n",
            "{'loss': 0.0073, 'grad_norm': 0.6650664806365967, 'learning_rate': 7.3939337406526444e-06, 'epoch': 4.68}\n",
            "{'loss': 0.0098, 'grad_norm': 0.2837924659252167, 'learning_rate': 7.392379086796326e-06, 'epoch': 4.69}\n",
            "{'loss': 0.0082, 'grad_norm': 0.46468809247016907, 'learning_rate': 7.390824432940007e-06, 'epoch': 4.69}\n",
            "{'loss': 0.0078, 'grad_norm': 0.32635554671287537, 'learning_rate': 7.389269779083688e-06, 'epoch': 4.69}\n",
            "{'loss': 0.0092, 'grad_norm': 0.25622159242630005, 'learning_rate': 7.387715125227368e-06, 'epoch': 4.69}\n",
            "{'loss': 0.0082, 'grad_norm': 0.4671611785888672, 'learning_rate': 7.38616047137105e-06, 'epoch': 4.69}\n",
            "{'loss': 0.0082, 'grad_norm': 0.35476261377334595, 'learning_rate': 7.384605817514731e-06, 'epoch': 4.7}\n",
            "{'loss': 0.0086, 'grad_norm': 0.24378754198551178, 'learning_rate': 7.383051163658413e-06, 'epoch': 4.7}\n",
            "{'loss': 0.0083, 'grad_norm': 0.49413448572158813, 'learning_rate': 7.381496509802093e-06, 'epoch': 4.7}\n",
            "{'loss': 0.0097, 'grad_norm': 0.6255208253860474, 'learning_rate': 7.379941855945775e-06, 'epoch': 4.7}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "45a1d91ca0d54a74a8c73f530d70cbea",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/87 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.12334992736577988, 'eval_wer': 22.869861220214716, 'eval_runtime': 708.6624, 'eval_samples_per_second': 1.943, 'eval_steps_per_second': 0.123, 'epoch': 4.7}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/kd/anaconda3/envs/ai4bharat/lib/python3.12/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.007, 'grad_norm': 0.35769912600517273, 'learning_rate': 7.3783872020894555e-06, 'epoch': 4.7}\n",
            "{'loss': 0.0079, 'grad_norm': 0.4075803756713867, 'learning_rate': 7.376832548233136e-06, 'epoch': 4.71}\n",
            "{'loss': 0.0084, 'grad_norm': 0.5245373845100403, 'learning_rate': 7.375277894376818e-06, 'epoch': 4.71}\n",
            "{'loss': 0.0073, 'grad_norm': 0.3938024640083313, 'learning_rate': 7.373723240520498e-06, 'epoch': 4.71}\n",
            "{'loss': 0.0078, 'grad_norm': 0.29685312509536743, 'learning_rate': 7.37216858666418e-06, 'epoch': 4.71}\n",
            "{'loss': 0.0073, 'grad_norm': 0.3758625090122223, 'learning_rate': 7.3706139328078606e-06, 'epoch': 4.71}\n",
            "{'loss': 0.0084, 'grad_norm': 0.29927384853363037, 'learning_rate': 7.369059278951543e-06, 'epoch': 4.71}\n",
            "{'loss': 0.008, 'grad_norm': 0.5142597556114197, 'learning_rate': 7.367504625095223e-06, 'epoch': 4.72}\n",
            "{'loss': 0.0073, 'grad_norm': 0.420284241437912, 'learning_rate': 7.365949971238904e-06, 'epoch': 4.72}\n",
            "{'loss': 0.0083, 'grad_norm': 0.34180015325546265, 'learning_rate': 7.364395317382585e-06, 'epoch': 4.72}\n",
            "{'loss': 0.0068, 'grad_norm': 0.32192564010620117, 'learning_rate': 7.3628406635262665e-06, 'epoch': 4.72}\n",
            "{'loss': 0.008, 'grad_norm': 0.36060991883277893, 'learning_rate': 7.361286009669948e-06, 'epoch': 4.72}\n",
            "{'loss': 0.0073, 'grad_norm': 0.3486025333404541, 'learning_rate': 7.359731355813629e-06, 'epoch': 4.73}\n",
            "{'loss': 0.0082, 'grad_norm': 0.3214672803878784, 'learning_rate': 7.35817670195731e-06, 'epoch': 4.73}\n",
            "{'loss': 0.0064, 'grad_norm': 0.4413493275642395, 'learning_rate': 7.356622048100991e-06, 'epoch': 4.73}\n",
            "{'loss': 0.0077, 'grad_norm': 0.43926751613616943, 'learning_rate': 7.355067394244672e-06, 'epoch': 4.73}\n",
            "{'loss': 0.0076, 'grad_norm': 0.5460909008979797, 'learning_rate': 7.353512740388354e-06, 'epoch': 4.73}\n",
            "{'loss': 0.0092, 'grad_norm': 0.3185432255268097, 'learning_rate': 7.351958086532034e-06, 'epoch': 4.74}\n",
            "{'loss': 0.0069, 'grad_norm': 0.2319188266992569, 'learning_rate': 7.350403432675716e-06, 'epoch': 4.74}\n",
            "{'loss': 0.0074, 'grad_norm': 0.5871149897575378, 'learning_rate': 7.348848778819396e-06, 'epoch': 4.74}\n",
            "{'loss': 0.0087, 'grad_norm': 0.37313583493232727, 'learning_rate': 7.347294124963078e-06, 'epoch': 4.74}\n",
            "{'loss': 0.0089, 'grad_norm': 0.647507905960083, 'learning_rate': 7.345739471106759e-06, 'epoch': 4.74}\n",
            "{'loss': 0.0082, 'grad_norm': 0.27601006627082825, 'learning_rate': 7.344184817250439e-06, 'epoch': 4.75}\n",
            "{'loss': 0.0073, 'grad_norm': 0.28716638684272766, 'learning_rate': 7.342630163394121e-06, 'epoch': 4.75}\n",
            "{'loss': 0.0077, 'grad_norm': 0.5942812561988831, 'learning_rate': 7.3410755095378014e-06, 'epoch': 4.75}\n",
            "{'loss': 0.0084, 'grad_norm': 0.15697385370731354, 'learning_rate': 7.3395208556814835e-06, 'epoch': 4.75}\n",
            "{'loss': 0.0069, 'grad_norm': 0.2953414022922516, 'learning_rate': 7.337966201825164e-06, 'epoch': 4.75}\n",
            "{'loss': 0.0089, 'grad_norm': 0.3311692178249359, 'learning_rate': 7.336411547968846e-06, 'epoch': 4.76}\n",
            "{'loss': 0.0071, 'grad_norm': 0.45074373483657837, 'learning_rate': 7.334856894112526e-06, 'epoch': 4.76}\n",
            "{'loss': 0.0087, 'grad_norm': 0.40566280484199524, 'learning_rate': 7.333302240256207e-06, 'epoch': 4.76}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1268db5b6c0f4c5988db2e2a01709be9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/87 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.1210826113820076, 'eval_wer': 22.487562189054728, 'eval_runtime': 713.7052, 'eval_samples_per_second': 1.929, 'eval_steps_per_second': 0.122, 'epoch': 4.76}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/kd/anaconda3/envs/ai4bharat/lib/python3.12/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.0073, 'grad_norm': 0.37084391713142395, 'learning_rate': 7.3317475863998886e-06, 'epoch': 4.76}\n",
            "{'loss': 0.0098, 'grad_norm': 0.6135252714157104, 'learning_rate': 7.33019293254357e-06, 'epoch': 4.76}\n",
            "{'loss': 0.0094, 'grad_norm': 0.5940226912498474, 'learning_rate': 7.328638278687251e-06, 'epoch': 4.77}\n",
            "{'loss': 0.0071, 'grad_norm': 0.47798827290534973, 'learning_rate': 7.327083624830932e-06, 'epoch': 4.77}\n",
            "{'loss': 0.0071, 'grad_norm': 0.6975281834602356, 'learning_rate': 7.325528970974613e-06, 'epoch': 4.77}\n",
            "{'loss': 0.0093, 'grad_norm': 0.4472569525241852, 'learning_rate': 7.3239743171182945e-06, 'epoch': 4.77}\n",
            "{'loss': 0.0061, 'grad_norm': 0.2454708069562912, 'learning_rate': 7.322419663261975e-06, 'epoch': 4.77}\n",
            "{'loss': 0.0071, 'grad_norm': 0.19155797362327576, 'learning_rate': 7.320865009405657e-06, 'epoch': 4.78}\n",
            "{'loss': 0.0094, 'grad_norm': 0.363675594329834, 'learning_rate': 7.319310355549337e-06, 'epoch': 4.78}\n",
            "{'loss': 0.0088, 'grad_norm': 0.43237408995628357, 'learning_rate': 7.317755701693019e-06, 'epoch': 4.78}\n",
            "{'loss': 0.0069, 'grad_norm': 0.3517273962497711, 'learning_rate': 7.3162010478367e-06, 'epoch': 4.78}\n",
            "{'loss': 0.0082, 'grad_norm': 0.5403612852096558, 'learning_rate': 7.314646393980382e-06, 'epoch': 4.78}\n",
            "{'loss': 0.0081, 'grad_norm': 0.3555890917778015, 'learning_rate': 7.313091740124062e-06, 'epoch': 4.79}\n",
            "{'loss': 0.0081, 'grad_norm': 0.4156258702278137, 'learning_rate': 7.311537086267742e-06, 'epoch': 4.79}\n",
            "{'loss': 0.0081, 'grad_norm': 0.3629215955734253, 'learning_rate': 7.309982432411424e-06, 'epoch': 4.79}\n",
            "{'loss': 0.0074, 'grad_norm': 0.4878790080547333, 'learning_rate': 7.308427778555105e-06, 'epoch': 4.79}\n",
            "{'loss': 0.0077, 'grad_norm': 0.4477733373641968, 'learning_rate': 7.306873124698787e-06, 'epoch': 4.79}\n",
            "{'loss': 0.0077, 'grad_norm': 0.31901049613952637, 'learning_rate': 7.305318470842467e-06, 'epoch': 4.8}\n",
            "{'loss': 0.0065, 'grad_norm': 0.30526813864707947, 'learning_rate': 7.303763816986149e-06, 'epoch': 4.8}\n",
            "{'loss': 0.0074, 'grad_norm': 0.2573339641094208, 'learning_rate': 7.3022091631298294e-06, 'epoch': 4.8}\n",
            "{'loss': 0.0071, 'grad_norm': 0.43238797783851624, 'learning_rate': 7.300654509273511e-06, 'epoch': 4.8}\n",
            "{'loss': 0.0074, 'grad_norm': 0.4412781000137329, 'learning_rate': 7.299099855417192e-06, 'epoch': 4.8}\n",
            "{'loss': 0.0069, 'grad_norm': 0.39864736795425415, 'learning_rate': 7.297545201560873e-06, 'epoch': 4.81}\n",
            "{'loss': 0.0096, 'grad_norm': 0.656860888004303, 'learning_rate': 7.295990547704554e-06, 'epoch': 4.81}\n",
            "{'loss': 0.0083, 'grad_norm': 0.31491604447364807, 'learning_rate': 7.294435893848235e-06, 'epoch': 4.81}\n",
            "{'loss': 0.0085, 'grad_norm': 0.3036039173603058, 'learning_rate': 7.2928812399919166e-06, 'epoch': 4.81}\n",
            "{'loss': 0.0076, 'grad_norm': 0.285432904958725, 'learning_rate': 7.291326586135598e-06, 'epoch': 4.81}\n",
            "{'loss': 0.0084, 'grad_norm': 0.3833303153514862, 'learning_rate': 7.289771932279278e-06, 'epoch': 4.81}\n",
            "{'loss': 0.0084, 'grad_norm': 0.4162202775478363, 'learning_rate': 7.28821727842296e-06, 'epoch': 4.82}\n",
            "{'loss': 0.0074, 'grad_norm': 0.6495001912117004, 'learning_rate': 7.2866626245666405e-06, 'epoch': 4.82}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "700c26dc4f4548c7a9b4fda49571346f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/87 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.12240738421678543, 'eval_wer': 22.66038229903116, 'eval_runtime': 717.2583, 'eval_samples_per_second': 1.92, 'eval_steps_per_second': 0.121, 'epoch': 4.82}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/kd/anaconda3/envs/ai4bharat/lib/python3.12/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.007, 'grad_norm': 0.3588666319847107, 'learning_rate': 7.2851079707103225e-06, 'epoch': 4.82}\n",
            "{'loss': 0.0078, 'grad_norm': 0.3393179178237915, 'learning_rate': 7.283553316854003e-06, 'epoch': 4.82}\n",
            "{'loss': 0.0064, 'grad_norm': 0.5209755897521973, 'learning_rate': 7.281998662997685e-06, 'epoch': 4.82}\n",
            "{'loss': 0.0072, 'grad_norm': 0.2635524272918701, 'learning_rate': 7.280444009141365e-06, 'epoch': 4.83}\n",
            "{'loss': 0.0083, 'grad_norm': 0.2511845529079437, 'learning_rate': 7.2788893552850456e-06, 'epoch': 4.83}\n",
            "{'loss': 0.0079, 'grad_norm': 0.25292831659317017, 'learning_rate': 7.277334701428728e-06, 'epoch': 4.83}\n",
            "{'loss': 0.007, 'grad_norm': 0.2662090063095093, 'learning_rate': 7.275780047572408e-06, 'epoch': 4.83}\n",
            "{'loss': 0.0077, 'grad_norm': 0.6227190494537354, 'learning_rate': 7.27422539371609e-06, 'epoch': 4.83}\n",
            "{'loss': 0.007, 'grad_norm': 0.38415369391441345, 'learning_rate': 7.27267073985977e-06, 'epoch': 4.84}\n",
            "{'loss': 0.0079, 'grad_norm': 0.2881843149662018, 'learning_rate': 7.271116086003452e-06, 'epoch': 4.84}\n",
            "{'loss': 0.0074, 'grad_norm': 0.5481384992599487, 'learning_rate': 7.269561432147133e-06, 'epoch': 4.84}\n",
            "{'loss': 0.0067, 'grad_norm': 0.24230733513832092, 'learning_rate': 7.268006778290814e-06, 'epoch': 4.84}\n",
            "{'loss': 0.0089, 'grad_norm': 0.6049771904945374, 'learning_rate': 7.266452124434495e-06, 'epoch': 4.84}\n",
            "{'loss': 0.0093, 'grad_norm': 0.5214815139770508, 'learning_rate': 7.264897470578176e-06, 'epoch': 4.85}\n",
            "{'loss': 0.0083, 'grad_norm': 0.2968074083328247, 'learning_rate': 7.2633428167218574e-06, 'epoch': 4.85}\n",
            "{'loss': 0.0077, 'grad_norm': 0.3719962239265442, 'learning_rate': 7.261788162865539e-06, 'epoch': 4.85}\n",
            "{'loss': 0.0083, 'grad_norm': 0.385922908782959, 'learning_rate': 7.26023350900922e-06, 'epoch': 4.85}\n",
            "{'loss': 0.008, 'grad_norm': 0.2307748794555664, 'learning_rate': 7.258678855152901e-06, 'epoch': 4.85}\n",
            "{'loss': 0.0066, 'grad_norm': 0.3382638990879059, 'learning_rate': 7.257124201296581e-06, 'epoch': 4.86}\n",
            "{'loss': 0.0077, 'grad_norm': 0.9389706254005432, 'learning_rate': 7.255569547440263e-06, 'epoch': 4.86}\n",
            "{'loss': 0.0089, 'grad_norm': 0.3609180152416229, 'learning_rate': 7.254014893583944e-06, 'epoch': 4.86}\n",
            "{'loss': 0.0082, 'grad_norm': 0.2744644284248352, 'learning_rate': 7.252460239727626e-06, 'epoch': 4.86}\n",
            "{'loss': 0.0081, 'grad_norm': 0.351519376039505, 'learning_rate': 7.250905585871306e-06, 'epoch': 4.86}\n",
            "{'loss': 0.0093, 'grad_norm': 0.25927257537841797, 'learning_rate': 7.249350932014988e-06, 'epoch': 4.87}\n",
            "{'loss': 0.0077, 'grad_norm': 0.312317430973053, 'learning_rate': 7.2477962781586685e-06, 'epoch': 4.87}\n",
            "{'loss': 0.009, 'grad_norm': 0.3662896156311035, 'learning_rate': 7.246241624302349e-06, 'epoch': 4.87}\n",
            "{'loss': 0.0089, 'grad_norm': 0.44481420516967773, 'learning_rate': 7.244686970446031e-06, 'epoch': 4.87}\n",
            "{'loss': 0.0078, 'grad_norm': 0.30439838767051697, 'learning_rate': 7.243132316589712e-06, 'epoch': 4.87}\n",
            "{'loss': 0.0077, 'grad_norm': 0.24437308311462402, 'learning_rate': 7.241577662733393e-06, 'epoch': 4.88}\n",
            "{'loss': 0.0087, 'grad_norm': 0.36201614141464233, 'learning_rate': 7.240023008877074e-06, 'epoch': 4.88}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "81f8e20fa7404431b5ed5ff34d203a7f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/87 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.12375559657812119, 'eval_wer': 22.822728462948415, 'eval_runtime': 709.8061, 'eval_samples_per_second': 1.94, 'eval_steps_per_second': 0.123, 'epoch': 4.88}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/kd/anaconda3/envs/ai4bharat/lib/python3.12/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.0069, 'grad_norm': 0.5253505110740662, 'learning_rate': 7.238468355020756e-06, 'epoch': 4.88}\n",
            "{'loss': 0.0079, 'grad_norm': 0.5392888784408569, 'learning_rate': 7.236913701164437e-06, 'epoch': 4.88}\n",
            "{'loss': 0.0078, 'grad_norm': 0.267925500869751, 'learning_rate': 7.235359047308117e-06, 'epoch': 4.88}\n",
            "{'loss': 0.0079, 'grad_norm': 0.4301277697086334, 'learning_rate': 7.233804393451799e-06, 'epoch': 4.89}\n",
            "{'loss': 0.0074, 'grad_norm': 0.33917436003685, 'learning_rate': 7.2322497395954795e-06, 'epoch': 4.89}\n",
            "{'loss': 0.0077, 'grad_norm': 0.410214364528656, 'learning_rate': 7.2306950857391615e-06, 'epoch': 4.89}\n",
            "{'loss': 0.0089, 'grad_norm': 0.31522613763809204, 'learning_rate': 7.229140431882842e-06, 'epoch': 4.89}\n",
            "{'loss': 0.0093, 'grad_norm': 0.24343495070934296, 'learning_rate': 7.227585778026524e-06, 'epoch': 4.89}\n",
            "{'loss': 0.0082, 'grad_norm': 0.3026169538497925, 'learning_rate': 7.226031124170204e-06, 'epoch': 4.9}\n",
            "{'loss': 0.0077, 'grad_norm': 0.43159201741218567, 'learning_rate': 7.224476470313885e-06, 'epoch': 4.9}\n",
            "{'loss': 0.0078, 'grad_norm': 0.38107356429100037, 'learning_rate': 7.222921816457567e-06, 'epoch': 4.9}\n",
            "{'loss': 0.0088, 'grad_norm': 0.21906816959381104, 'learning_rate': 7.221367162601247e-06, 'epoch': 4.9}\n",
            "{'loss': 0.0081, 'grad_norm': 0.47447019815444946, 'learning_rate': 7.219812508744929e-06, 'epoch': 4.9}\n",
            "{'loss': 0.0072, 'grad_norm': 0.23169350624084473, 'learning_rate': 7.218257854888609e-06, 'epoch': 4.9}\n",
            "{'loss': 0.0066, 'grad_norm': 0.2366666942834854, 'learning_rate': 7.216703201032291e-06, 'epoch': 4.91}\n",
            "{'loss': 0.0081, 'grad_norm': 0.3316698372364044, 'learning_rate': 7.215148547175972e-06, 'epoch': 4.91}\n",
            "{'loss': 0.007, 'grad_norm': 0.328724205493927, 'learning_rate': 7.213593893319653e-06, 'epoch': 4.91}\n",
            "{'loss': 0.0081, 'grad_norm': 0.2940307557582855, 'learning_rate': 7.212039239463334e-06, 'epoch': 4.91}\n",
            "{'loss': 0.0067, 'grad_norm': 0.2827185094356537, 'learning_rate': 7.210484585607015e-06, 'epoch': 4.91}\n",
            "{'loss': 0.0084, 'grad_norm': 0.3375036120414734, 'learning_rate': 7.2089299317506965e-06, 'epoch': 4.92}\n",
            "{'loss': 0.0092, 'grad_norm': 0.1956796497106552, 'learning_rate': 7.207375277894378e-06, 'epoch': 4.92}\n",
            "{'loss': 0.0084, 'grad_norm': 0.4630436897277832, 'learning_rate': 7.205820624038059e-06, 'epoch': 4.92}\n",
            "{'loss': 0.0086, 'grad_norm': 0.44376280903816223, 'learning_rate': 7.20426597018174e-06, 'epoch': 4.92}\n",
            "{'loss': 0.0068, 'grad_norm': 0.2640768885612488, 'learning_rate': 7.20271131632542e-06, 'epoch': 4.92}\n",
            "{'loss': 0.0076, 'grad_norm': 0.5944268107414246, 'learning_rate': 7.201156662469102e-06, 'epoch': 4.93}\n",
            "{'loss': 0.009, 'grad_norm': 0.4520888030529022, 'learning_rate': 7.199602008612783e-06, 'epoch': 4.93}\n",
            "{'loss': 0.0075, 'grad_norm': 0.7817387580871582, 'learning_rate': 7.198047354756465e-06, 'epoch': 4.93}\n",
            "{'loss': 0.0073, 'grad_norm': 0.26423606276512146, 'learning_rate': 7.196492700900145e-06, 'epoch': 4.93}\n",
            "{'loss': 0.0088, 'grad_norm': 0.5687022805213928, 'learning_rate': 7.194938047043827e-06, 'epoch': 4.93}\n",
            "{'loss': 0.0077, 'grad_norm': 0.45082318782806396, 'learning_rate': 7.1933833931875075e-06, 'epoch': 4.94}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "afc5aed2b285493aa64eeb9687874be1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/87 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.12126901000738144, 'eval_wer': 22.47185126996596, 'eval_runtime': 714.5051, 'eval_samples_per_second': 1.927, 'eval_steps_per_second': 0.122, 'epoch': 4.94}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/kd/anaconda3/envs/ai4bharat/lib/python3.12/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.0061, 'grad_norm': 0.6415086388587952, 'learning_rate': 7.191828739331188e-06, 'epoch': 4.94}\n",
            "{'loss': 0.0074, 'grad_norm': 0.32522374391555786, 'learning_rate': 7.19027408547487e-06, 'epoch': 4.94}\n",
            "{'loss': 0.0071, 'grad_norm': 0.29529234766960144, 'learning_rate': 7.18871943161855e-06, 'epoch': 4.94}\n",
            "{'loss': 0.0084, 'grad_norm': 0.22181645035743713, 'learning_rate': 7.187164777762232e-06, 'epoch': 4.94}\n",
            "{'loss': 0.0087, 'grad_norm': 0.43777039647102356, 'learning_rate': 7.185610123905913e-06, 'epoch': 4.95}\n",
            "{'loss': 0.008, 'grad_norm': 0.5305862426757812, 'learning_rate': 7.184055470049595e-06, 'epoch': 4.95}\n",
            "{'loss': 0.0084, 'grad_norm': 0.3092014789581299, 'learning_rate': 7.182500816193275e-06, 'epoch': 4.95}\n",
            "{'loss': 0.0083, 'grad_norm': 0.27762675285339355, 'learning_rate': 7.180946162336956e-06, 'epoch': 4.95}\n",
            "{'loss': 0.0082, 'grad_norm': 0.24796375632286072, 'learning_rate': 7.179391508480637e-06, 'epoch': 4.95}\n",
            "{'loss': 0.0087, 'grad_norm': 0.3682677447795868, 'learning_rate': 7.1778368546243185e-06, 'epoch': 4.96}\n",
            "{'loss': 0.0077, 'grad_norm': 0.31179627776145935, 'learning_rate': 7.176282200768e-06, 'epoch': 4.96}\n",
            "{'loss': 0.0063, 'grad_norm': 0.43482494354248047, 'learning_rate': 7.174727546911681e-06, 'epoch': 4.96}\n",
            "{'loss': 0.008, 'grad_norm': 0.5940544009208679, 'learning_rate': 7.173172893055362e-06, 'epoch': 4.96}\n",
            "{'loss': 0.0093, 'grad_norm': 0.3628237843513489, 'learning_rate': 7.171618239199043e-06, 'epoch': 4.96}\n",
            "{'loss': 0.0087, 'grad_norm': 0.3247573971748352, 'learning_rate': 7.170063585342724e-06, 'epoch': 4.97}\n",
            "{'loss': 0.0076, 'grad_norm': 0.3032718002796173, 'learning_rate': 7.168508931486406e-06, 'epoch': 4.97}\n",
            "{'loss': 0.007, 'grad_norm': 0.3608975410461426, 'learning_rate': 7.166954277630086e-06, 'epoch': 4.97}\n",
            "{'loss': 0.0086, 'grad_norm': 0.39400172233581543, 'learning_rate': 7.165399623773768e-06, 'epoch': 4.97}\n",
            "{'loss': 0.0082, 'grad_norm': 0.3323216140270233, 'learning_rate': 7.163844969917448e-06, 'epoch': 4.97}\n",
            "{'loss': 0.0095, 'grad_norm': 0.5297073125839233, 'learning_rate': 7.16229031606113e-06, 'epoch': 4.98}\n",
            "{'loss': 0.0085, 'grad_norm': 0.38768526911735535, 'learning_rate': 7.160735662204811e-06, 'epoch': 4.98}\n",
            "{'loss': 0.0086, 'grad_norm': 0.33927035331726074, 'learning_rate': 7.159181008348491e-06, 'epoch': 4.98}\n",
            "{'loss': 0.0078, 'grad_norm': 0.25451040267944336, 'learning_rate': 7.157626354492173e-06, 'epoch': 4.98}\n",
            "{'loss': 0.009, 'grad_norm': 0.6278488039970398, 'learning_rate': 7.1560717006358535e-06, 'epoch': 4.98}\n",
            "{'loss': 0.0063, 'grad_norm': 0.25517037510871887, 'learning_rate': 7.1545170467795355e-06, 'epoch': 4.99}\n",
            "{'loss': 0.0071, 'grad_norm': 0.2723008990287781, 'learning_rate': 7.152962392923216e-06, 'epoch': 4.99}\n",
            "{'loss': 0.0092, 'grad_norm': 0.28526952862739563, 'learning_rate': 7.151407739066898e-06, 'epoch': 4.99}\n",
            "{'loss': 0.0079, 'grad_norm': 0.3839491307735443, 'learning_rate': 7.149853085210578e-06, 'epoch': 4.99}\n",
            "{'loss': 0.0099, 'grad_norm': 0.38129690289497375, 'learning_rate': 7.148298431354259e-06, 'epoch': 4.99}\n",
            "{'loss': 0.0081, 'grad_norm': 0.31060513854026794, 'learning_rate': 7.146743777497941e-06, 'epoch': 5.0}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fa59a28a71e246ca83420ee3a42e8caf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/87 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.12186864018440247, 'eval_wer': 23.812516365540716, 'eval_runtime': 715.8765, 'eval_samples_per_second': 1.924, 'eval_steps_per_second': 0.122, 'epoch': 5.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/kd/anaconda3/envs/ai4bharat/lib/python3.12/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.0066, 'grad_norm': 0.42147165536880493, 'learning_rate': 7.145189123641622e-06, 'epoch': 5.0}\n",
            "{'loss': 0.0073, 'grad_norm': 0.3396463990211487, 'learning_rate': 7.143634469785303e-06, 'epoch': 5.0}\n",
            "{'loss': 0.0063, 'grad_norm': 0.30866605043411255, 'learning_rate': 7.142079815928984e-06, 'epoch': 5.0}\n",
            "{'loss': 0.0043, 'grad_norm': 0.1845177412033081, 'learning_rate': 7.1405251620726645e-06, 'epoch': 5.0}\n",
            "{'loss': 0.0047, 'grad_norm': 0.4276714622974396, 'learning_rate': 7.1389705082163465e-06, 'epoch': 5.0}\n",
            "{'loss': 0.0041, 'grad_norm': 0.25747573375701904, 'learning_rate': 7.137415854360027e-06, 'epoch': 5.01}\n",
            "{'loss': 0.0042, 'grad_norm': 0.22489076852798462, 'learning_rate': 7.135861200503709e-06, 'epoch': 5.01}\n",
            "{'loss': 0.0039, 'grad_norm': 0.23922201991081238, 'learning_rate': 7.134306546647389e-06, 'epoch': 5.01}\n",
            "{'loss': 0.0041, 'grad_norm': 0.320127934217453, 'learning_rate': 7.132751892791071e-06, 'epoch': 5.01}\n",
            "{'loss': 0.0045, 'grad_norm': 0.5351852774620056, 'learning_rate': 7.131197238934752e-06, 'epoch': 5.01}\n",
            "{'loss': 0.0054, 'grad_norm': 0.37381741404533386, 'learning_rate': 7.129642585078432e-06, 'epoch': 5.02}\n",
            "{'loss': 0.0049, 'grad_norm': 0.29086896777153015, 'learning_rate': 7.128087931222114e-06, 'epoch': 5.02}\n",
            "{'loss': 0.0043, 'grad_norm': 0.3392098844051361, 'learning_rate': 7.126533277365794e-06, 'epoch': 5.02}\n",
            "{'loss': 0.004, 'grad_norm': 0.3186517655849457, 'learning_rate': 7.124978623509476e-06, 'epoch': 5.02}\n",
            "{'loss': 0.0043, 'grad_norm': 0.31869420409202576, 'learning_rate': 7.123423969653157e-06, 'epoch': 5.02}\n",
            "{'loss': 0.0046, 'grad_norm': 0.3311465382575989, 'learning_rate': 7.121869315796839e-06, 'epoch': 5.03}\n",
            "{'loss': 0.0043, 'grad_norm': 0.32089298963546753, 'learning_rate': 7.120314661940519e-06, 'epoch': 5.03}\n",
            "{'loss': 0.0043, 'grad_norm': 0.3044368326663971, 'learning_rate': 7.1187600080842e-06, 'epoch': 5.03}\n",
            "{'loss': 0.0043, 'grad_norm': 0.24406185746192932, 'learning_rate': 7.1172053542278815e-06, 'epoch': 5.03}\n",
            "{'loss': 0.0044, 'grad_norm': 0.35217636823654175, 'learning_rate': 7.115650700371563e-06, 'epoch': 5.03}\n",
            "{'loss': 0.0054, 'grad_norm': 0.2782202661037445, 'learning_rate': 7.114096046515244e-06, 'epoch': 5.04}\n",
            "{'loss': 0.0052, 'grad_norm': 0.2774098217487335, 'learning_rate': 7.112541392658925e-06, 'epoch': 5.04}\n",
            "{'loss': 0.005, 'grad_norm': 0.2628326416015625, 'learning_rate': 7.110986738802606e-06, 'epoch': 5.04}\n",
            "{'loss': 0.0047, 'grad_norm': 0.18418872356414795, 'learning_rate': 7.109432084946287e-06, 'epoch': 5.04}\n",
            "{'loss': 0.0044, 'grad_norm': 0.19020070135593414, 'learning_rate': 7.107877431089968e-06, 'epoch': 5.04}\n",
            "{'loss': 0.004, 'grad_norm': 0.16571703553199768, 'learning_rate': 7.10632277723365e-06, 'epoch': 5.05}\n",
            "{'loss': 0.0049, 'grad_norm': 0.32185056805610657, 'learning_rate': 7.10476812337733e-06, 'epoch': 5.05}\n",
            "{'loss': 0.0043, 'grad_norm': 0.5220110416412354, 'learning_rate': 7.103213469521012e-06, 'epoch': 5.05}\n",
            "{'loss': 0.0041, 'grad_norm': 0.2699016034603119, 'learning_rate': 7.1016588156646925e-06, 'epoch': 5.05}\n",
            "{'loss': 0.0042, 'grad_norm': 0.44441714882850647, 'learning_rate': 7.1001041618083745e-06, 'epoch': 5.05}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1e6de4adc802467eaf129fae51d4da4c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/87 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.13604962825775146, 'eval_wer': 22.66038229903116, 'eval_runtime': 715.5026, 'eval_samples_per_second': 1.925, 'eval_steps_per_second': 0.122, 'epoch': 5.05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/kd/anaconda3/envs/ai4bharat/lib/python3.12/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.0045, 'grad_norm': 0.36925995349884033, 'learning_rate': 7.098549507952055e-06, 'epoch': 5.06}\n",
            "{'loss': 0.0046, 'grad_norm': 0.20429135859012604, 'learning_rate': 7.096994854095735e-06, 'epoch': 5.06}\n",
            "{'loss': 0.0042, 'grad_norm': 0.3561585545539856, 'learning_rate': 7.095440200239417e-06, 'epoch': 5.06}\n",
            "{'loss': 0.0042, 'grad_norm': 0.28357240557670593, 'learning_rate': 7.093885546383098e-06, 'epoch': 5.06}\n",
            "{'loss': 0.004, 'grad_norm': 0.34664955735206604, 'learning_rate': 7.09233089252678e-06, 'epoch': 5.06}\n",
            "{'loss': 0.0052, 'grad_norm': 0.22231252491474152, 'learning_rate': 7.09077623867046e-06, 'epoch': 5.07}\n",
            "{'loss': 0.0045, 'grad_norm': 0.200051411986351, 'learning_rate': 7.089221584814142e-06, 'epoch': 5.07}\n",
            "{'loss': 0.0041, 'grad_norm': 0.27804526686668396, 'learning_rate': 7.087666930957823e-06, 'epoch': 5.07}\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/home/kd/Desktop/proj/apr/Punjabi_ASR/checkpoints/whisper/whisper-medium-pa/checkpoint-19800\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/anaconda3/envs/ai4bharat/lib/python3.12/site-packages/transformers/trainer.py:1780\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1778\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1780\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1781\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1782\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1783\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1784\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1785\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/anaconda3/envs/ai4bharat/lib/python3.12/site-packages/transformers/trainer.py:2118\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2115\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   2117\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 2118\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2121\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2122\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2123\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2124\u001b[0m ):\n\u001b[1;32m   2125\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2126\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
            "File \u001b[0;32m~/anaconda3/envs/ai4bharat/lib/python3.12/site-packages/transformers/trainer.py:3045\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   3043\u001b[0m         scaled_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m   3044\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3045\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3047\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach() \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps\n",
            "File \u001b[0;32m~/anaconda3/envs/ai4bharat/lib/python3.12/site-packages/accelerate/accelerator.py:2125\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   2123\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlomo_backward(loss, learning_rate)\n\u001b[1;32m   2124\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2125\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/anaconda3/envs/ai4bharat/lib/python3.12/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/anaconda3/envs/ai4bharat/lib/python3.12/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/anaconda3/envs/ai4bharat/lib/python3.12/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "trainer.train(resume_from_checkpoint='/home/kd/Desktop/proj/apr/Punjabi_ASR/checkpoints/whisper/whisper-medium-pa/checkpoint-19800')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce4c70ee",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9f61842",
      "metadata": {},
      "outputs": [],
      "source": [
        "# from transformers import AutoModelForCausalLM, GenerationConfig\n",
        "\n",
        "# model = AutoModelForCausalLM.from_pretrained(\"my_account/my_model\")\n",
        "# generation_config = GenerationConfig(\n",
        "#     max_new_tokens=50, do_sample=True, top_k=50, eos_token_id=model.config.eos_token_id\n",
        "# )\n",
        "# generation_config.save_pretrained(\"my_account/my_model\", push_to_hub=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7030622-caf7-4039-939b-6195cdaa2585",
      "metadata": {
        "id": "d7030622-caf7-4039-939b-6195cdaa2585"
      },
      "outputs": [],
      "source": [
        "trainer.push_to_hub()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0ace3aa-1ef3-45cb-933f-6ddca037c5aa",
      "metadata": {
        "id": "e0ace3aa-1ef3-45cb-933f-6ddca037c5aa"
      },
      "outputs": [],
      "source": [
        "# from transformers import pipeline\n",
        "# import gradio as gr\n",
        "\n",
        "# pipe = pipeline(model=\"sanchit-gandhi/whisper-small-hi\")  # change to \"your-username/the-name-you-picked\"\n",
        "\n",
        "# def transcribe(audio):\n",
        "#     text = pipe(audio)[\"text\"]\n",
        "#     return text\n",
        "\n",
        "# iface = gr.Interface(\n",
        "#     fn=transcribe,\n",
        "#     inputs=gr.Audio(source=\"microphone\", type=\"filepath\"),\n",
        "#     outputs=\"text\",\n",
        "#     title=\"Whisper Small Hindi\",\n",
        "#     description=\"Realtime demo for Hindi speech recognition using a fine-tuned Whisper small model.\",\n",
        "# )\n",
        "\n",
        "# iface.launch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da112383",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
