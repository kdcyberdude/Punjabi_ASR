{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from utils.alignment import align, load_align_model\n",
    "from speech_utils import load_audio, SAMPLE_RATE\n",
    "import IPython.display as ipd\n",
    "from tqdm import tqdm \n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.font_manager import FontProperties\n",
    "from datasets import load_from_disk, load_dataset, Audio\n",
    "import matplotlib.pyplot as plt\n",
    "import torchaudio.functional as F\n",
    "import re\n",
    "import numpy as np\n",
    "import speech_utils as su\n",
    "\n",
    "# ds_all = load_from_disk('/mnt/sea/speech/punjabi_asr_datasets/all_except_stt_yt')\n",
    "ds_all = load_from_disk('/mnt/pi/datasets/speech/yt_dataset')\n",
    "\n",
    "alignment_save_result_file_name = 'alignment_probs_for_x_ds.pkl'\n",
    "ds_all = ds_all.cast_column('audio', Audio(sampling_rate = 16000))\n",
    "\n",
    "ds = ds_all['train']\n",
    "print(ds)\n",
    "\n",
    "def show_example(i):\n",
    "    print(ds[i]['text'])\n",
    "    audio = ds[i]['audio']['array']\n",
    "    ipd.display(ipd.Audio(audio, rate=SAMPLE_RATE))\n",
    "\n",
    "print(ds[0])\n",
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "align_language = 'pa'\n",
    "align_model_base = 'kdcyberdude/w2v-bert-punjabi'\n",
    "align_model_verbatim = '/home/kd/Desktop/proj/apr/Punjabi_ASR/checkpoints/wav2vec2-bert-pa_indicvoice_verbatim_2/checkpoint-3500'\n",
    "\n",
    "results = []\n",
    "model_v, align_metadata_v, processor_v = load_align_model(align_language, device, model_name=align_model_verbatim)\n",
    "model_b, align_metadata_b, processor_b = load_align_model(align_language, device, model_name=align_model_base)\n",
    "\n",
    "# BOTH processors should be same\n",
    "assert processor_v.tokenizer.get_vocab() == processor_b.tokenizer.get_vocab()\n",
    "processor  = processor_v\n",
    "\n",
    "model_b.eval()\n",
    "model_v.eval()\n",
    "font_path = './AnmolUni.ttf'  \n",
    "from pathlib import Path\n",
    "font_path = Path(font_path)\n",
    "prop = FontProperties(fname=font_path)\n",
    "plt.rcParams['font.family'] = [\"Ubuntu\", prop.get_name()]\n",
    "\n",
    "sample = None\n",
    "for i in range(1000):\n",
    "    if ds[i]['duration'] < 5:\n",
    "        print(i)\n",
    "        sample = ds[i]\n",
    "        break\n",
    "\n",
    "print(sample)\n",
    "show_example(14)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unflatten(list_, lengths):\n",
    "    assert len(list_) == sum(lengths)\n",
    "    i = 0\n",
    "    ret = []\n",
    "    for l in lengths:\n",
    "        ret.append(list_[i : i + l])\n",
    "        i += l\n",
    "    return ret\n",
    "\n",
    "def align(emission, tokens, transcript):\n",
    "    try:\n",
    "        targets = torch.tensor([tokens], dtype=torch.int32, device=device)\n",
    "        if emission.shape[1] <= targets.shape[1]:\n",
    "            targets = targets[:, :-1] # remove leading * token\n",
    "            transcript = transcript[:-1]\n",
    "            if emission.shape[1] != targets.shape[1]:\n",
    "                targets = targets[:, 1:] # remove trailing * token\n",
    "                transcript = transcript[1:]\n",
    "        alignments, scores = F.forced_align(emission, targets, blank=0)\n",
    "\n",
    "        alignments, scores = alignments[0], scores[0]  # remove batch dimension \n",
    "        scores = scores.exp()  # convert back to probability\n",
    "    except RuntimeError as e:\n",
    "        print(f'Alignment failed for {len(tokens)} tokens and {emission.shape[1]} frames')\n",
    "        print(f'Alignment failed this will happen either there is no speech in the audio or the speech is very fast that even google STT cant transcribe it (manually checked and confirmed these cases)')\n",
    "        print(e)\n",
    "        raise ValueError('Alignment failed')\n",
    "    return alignments, scores, transcript, targets.shape[1]\n",
    "\n",
    "def compute_alignments(emission, transcript, dictionary):\n",
    "    # tokens = processor.tokenizer.encode(''.join(transcript))\n",
    "    tokens = [dictionary[char] for word in transcript for char in word]\n",
    "    alignment, scores, transcript, targets_shape = align(emission, tokens, transcript)\n",
    "    token_spans = F.merge_tokens(alignment, scores)\n",
    "    word_spans = unflatten(token_spans, [len(word) for word in transcript])\n",
    "    return word_spans, targets_shape\n",
    "\n",
    "\n",
    "# add a special '*' token to detect unaligned words or sequences in the transcript\n",
    "dictionary = processor.tokenizer.get_vocab()\n",
    "dictionary[\"*\"] = len(dictionary)\n",
    "vocab_chars = list(processor.tokenizer.get_vocab().keys())[3:-2]\n",
    "\n",
    "# Create a reverse dictionary to map numerical IDs back to their corresponding tokens.\n",
    "dic_rev = {v: k for k, v in dictionary.items()}\n",
    "\n",
    "# Define character replacements for specific Punjabi characters to their modified forms.\n",
    "replacements = {\n",
    "    'ਆ': 'ਅਾ',\n",
    "    'ਇ': 'ਿੲ',\n",
    "    'ਈ': 'ੲੀ',\n",
    "    'ਉ': 'ੳੁ',\n",
    "    'ਊ': 'ੳੂ',\n",
    "    'ਏ': 'ੲੇ',\n",
    "    'ਐ': 'ਅੈ',\n",
    "    'ਔ': 'ਅੌ',\n",
    "}\n",
    "\n",
    "normalize_chars = {\n",
    "    'ਭ': 'ਪ',\n",
    "    'ਫ਼': 'ਫ',\n",
    "    'ਜ਼': 'ਜ',\n",
    "    'ਗ਼': 'ਗ',\n",
    "    'ਖ਼': 'ਖ',\n",
    "    'ਸ਼': 'ਸ਼',\n",
    "    'ਲ਼': 'ਲ',\n",
    "    'ਣ': 'ਨ',\n",
    "    'ਓਂ': 'ਓ',\n",
    "}\n",
    "\n",
    "# List of Punjabi vowel signs (matras).\n",
    "matras = [ 'ਂ', '਼', 'ਾ', 'ਿ', 'ੀ', 'ੁ', 'ੂ', 'ੇ', 'ੈ', 'ੋ', 'ੌ', '੍', 'ੰ', 'ੱ']\n",
    "\n",
    "def process_star_transcript(text):\n",
    "    \"\"\"Process transcript by inserting '*' between words and at boundaries.\"\"\"\n",
    "    text = re.sub(r'\\s+', ' ', text.strip())\n",
    "    return f'* {text.replace(\" \", \" * \")} *'\n",
    "\n",
    "def get_word_spans(model, text, audio, debug=False):\n",
    "    \"\"\"Extract word spans from audio using a w2v-bert trained model on clean dataset.\"\"\"\n",
    "    if debug:\n",
    "        print(text)\n",
    "    transcript_words = text.split()\n",
    "    audio = torch.from_numpy(audio)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        input_features = processor(audio, sampling_rate=SAMPLE_RATE).input_features[0]\n",
    "        input_features = torch.tensor(input_features).to(device).unsqueeze(0)\n",
    "        emissions = model(input_features).logits\n",
    "        emissions = torch.log_softmax(emissions, dim=-1)\n",
    "    \n",
    "    pred_ids = torch.argmax(emissions, dim=-1)[0]\n",
    "    star_dim = torch.zeros((1, emissions.size(1), 1), device=emissions.device, dtype=emissions.dtype)\n",
    "    emissions = torch.cat((emissions, star_dim), 2)\n",
    "\n",
    "    word_spans, targets_shape = compute_alignments(emissions, transcript_words, dictionary)\n",
    "    return {'word_spans': word_spans, 'pred_ids': pred_ids, 'text_tokens_shape': targets_shape}\n",
    "\n",
    "\n",
    "def evaluate_predictions(words_map, deleted_words, replacements, matras, debug_infos, debug):\n",
    "    prev_next_word_overlap = {}\n",
    "    for i in range(len(words_map)):\n",
    "        current, current_type, current_score = words_map[i]\n",
    "        # Check phonetic context to potentially adjust scores\n",
    "        if current_type == 'word': #  and i > 0 and i < len(words_map) - 1\n",
    "            if i==0:\n",
    "                prev_word = ''\n",
    "                next_word = words_map[i+1][0]\n",
    "            elif i == len(words_map) - 1:\n",
    "                prev_word = words_map[i-1][0]\n",
    "                next_word = ''\n",
    "            else:\n",
    "                prev_word, next_word = words_map[i-1][0], words_map[i+1][0]\n",
    "            p_nc, p_nv, n_nc, n_nv = adjust_prob_based_on_context(current, prev_word, next_word, words_map, i, matras, debug_infos)\n",
    "            prev_next_word_overlap[i] = (p_nc, p_nv, n_nc, n_nv)\n",
    "        if current_type == 'deleted_word':\n",
    "            handle_deleted_word_cases(current, words_map, i, replacements, deleted_words, debug)\n",
    "\n",
    "    for d, idx in deleted_words:\n",
    "        if idx == 0:\n",
    "            pv = ''\n",
    "            nv = words_map[idx + 1][0]\n",
    "        elif idx == len(words_map) - 1:\n",
    "            pv = words_map[idx - 1][0]\n",
    "            nv = ''\n",
    "        else:\n",
    "            pv = words_map[idx - 1][0]\n",
    "            nv = words_map[idx + 1][0]\n",
    "        if ' ' in d and d.count(' ') == 1: # skip long deleted words\n",
    "            p,n = d.split()\n",
    "            if n == nv[:len(n)] or p == pv[-len(p):]:\n",
    "                deleted_words.remove((d, idx))\n",
    "        elif d in pv or d in nv:\n",
    "            deleted_words.remove((d, idx))\n",
    "\n",
    "def count_consonents_and_vowels(word):\n",
    "    consonents = 0\n",
    "    vowels = 0\n",
    "    for char in word:\n",
    "        if char in matras:\n",
    "            vowels += 1\n",
    "        else:\n",
    "            consonents += 1\n",
    "    return consonents, vowels\n",
    "\n",
    "def calculate_cons_vow_probs(nc, nv, p_nc, p_nv, n_nc, n_nv):\n",
    "    # Weightages\n",
    "    wc = 0.7  # weightage for consonants\n",
    "    wv = 0.3  # weightage for vowels\n",
    "    \n",
    "    # Calculate probabilities\n",
    "    if nc > 0 and nv > 0:\n",
    "        p_c = wc / nc\n",
    "        p_v = wv / nv\n",
    "    elif nc > 0:\n",
    "        p_c = (wc + wv) / nc\n",
    "        p_v = 0\n",
    "    elif nv > 0:\n",
    "        p_c = 0\n",
    "        p_v = (wc + wv) / nv\n",
    "    else:\n",
    "        p_c = 0\n",
    "        p_v = 0\n",
    "\n",
    "    prev_word_prob = p_nc * p_c + p_nv * p_v\n",
    "    nex_word_prob = n_nc * p_c + n_nv * p_v\n",
    "    \n",
    "    return prev_word_prob, nex_word_prob\n",
    "\n",
    "def normalize(word):\n",
    "    for k, v in normalize_chars.items():\n",
    "        word = word.replace(k, v)\n",
    "    return word\n",
    "\n",
    "def adjust_prob_based_on_context(current, prev_word, next_word, words_map, index, matras, debug_infos):\n",
    "    current = normalize(current)\n",
    "    prev_word = normalize(prev_word)\n",
    "    next_word = normalize(next_word)\n",
    "\n",
    "    p_nc, p_nv, n_nc, n_nv = 0, 0, 0, 0\n",
    "    # Punjabi specific nuances: understood by manually analyzing the results of the alignment\n",
    "    last_end_char = prev_word[-1] if prev_word else ''\n",
    "    next_first_char = next_word[0] if next_word else ''\n",
    "    star_prev_word = prev_word.split()[-1] if prev_word else ''\n",
    "    star_next_word = next_word.split()[0] if next_word else ''\n",
    "    if next_first_char in matras and len(next_word) > 1:\n",
    "        next_first_char = next_word[1]\n",
    "    nc, nv = count_consonents_and_vowels(current)\n",
    "        \n",
    "    matched_chars = ''\n",
    "    if star_prev_word != '' and star_prev_word in current:\n",
    "        matched_chars = star_prev_word\n",
    "    elif last_end_char == current[0]:\n",
    "        matched_chars = last_end_char\n",
    "    \n",
    "    p_nc, p_nv = count_consonents_and_vowels(matched_chars)\n",
    "    \n",
    "    matched_chars = ''\n",
    "    if star_next_word != '' and star_next_word in current:\n",
    "        matched_chars = star_next_word\n",
    "    elif next_first_char == current[-1]:\n",
    "        matched_chars = next_first_char\n",
    "    n_nc, n_nv = count_consonents_and_vowels(matched_chars)\n",
    "\n",
    "    prev_word_prob_adjustment, next_word_prob_adjustment = calculate_cons_vow_probs(nc, nv, p_nc, p_nv, n_nc, n_nv)\n",
    "    current_prob_adjustment = prev_word_prob_adjustment + next_word_prob_adjustment\n",
    "\n",
    "    _, type_, score_ = words_map[index]\n",
    "    # special case # ਆ (ਾ) => 0.25 * 2 = 0.5\n",
    "    if len(current) == 1:\n",
    "        words_map[index] = (current, type_, score_ * 2) \n",
    "        debug_infos[index] = debug_infos[index].replace('=>      Token Scores', f'=> [x*2][Single word] -> {(score_ * 2):.2f}     Token Scores')\n",
    "    if current_prob_adjustment > 0:\n",
    "        words_map[index] = (current, type_, score_ + current_prob_adjustment)\n",
    "        di_scores = ''\n",
    "        if prev_word_prob_adjustment > 0:\n",
    "            di_scores += f' + P:{prev_word_prob_adjustment:.2f}'\n",
    "        if next_word_prob_adjustment > 0:\n",
    "            di_scores += f' + N:{next_word_prob_adjustment:.2f}'\n",
    "        debug_infos[index] = debug_infos[index].replace('=>      Token Scores', f'=> [S:{score_:.2f} {di_scores}] -> {(score_ + current_prob_adjustment):.2f}     Token Scores')\n",
    "\n",
    "    return p_nc, p_nv, n_nc, n_nv\n",
    "\n",
    "def apply_replacements(word, replacements):\n",
    "    for k, v in replacements.items():\n",
    "        word = word.replace(k, v)\n",
    "    return word\n",
    "\n",
    "def handle_deleted_word_cases(current, words_map, index, replacements, deleted_words, debug):\n",
    "    # You can tweek these conditions to even detect a single extra phoneme - good for TTS... \n",
    "    if current.count(' ') == 2: # ਰ ਤੀ ਗ\n",
    "        current = current.split()[1]\n",
    "    if len(current) <= 2:\n",
    "        return # This is the case where * word is associated with at max 2 characters. It could be a phonetic component, fumble or a neighboring word\n",
    "    if ' '  in current and len(current) < 5:\n",
    "        return # Generally if a space is predicted in a star token word. Which basically signifies left and right side of space either belongs to neighouring words or new word is inserted; Example: 'ਹ ਹੈ' len:4 \n",
    "    if current in matras:\n",
    "        return # This is the case where a matra is predicted as a deleted word. This is not a valid case\n",
    "\n",
    "    if index == 0:\n",
    "        pv = ''\n",
    "        nv = words_map[index + 1][0]\n",
    "    elif index == len(words_map) - 1:\n",
    "        pv = words_map[index - 1][0]\n",
    "        nv = ''\n",
    "    else:\n",
    "        pv = words_map[index - 1][0]\n",
    "        nv = words_map[index + 1][0]\n",
    "\n",
    "    current = normalize(current)\n",
    "    pv = normalize(pv)\n",
    "    nv = normalize(nv)\n",
    "\n",
    "    # Further evaluation for deleted words involves checking if the deleted word fits well with surrounding context\n",
    "    # if index > 0 and index < len(words_map) - 1: # TODO: remove this\n",
    "    next_replaced = apply_replacements(nv, replacements)\n",
    "    prev_replaced = apply_replacements(pv, replacements)\n",
    "    if current not in pv and current not in prev_replaced and current not in nv and current not in next_replaced:\n",
    "        deleted_words.append((current, index))\n",
    "        if debug:\n",
    "            print(f'Deleted word is: {current}')\n",
    "   \n",
    "def process_word_scores(word, pred_ids, words_map, word_scores, star_token, debug):\n",
    "    scores = []\n",
    "    score_weights = []\n",
    "    tokens = []\n",
    "\n",
    "    debug_info = \"\"\n",
    "\n",
    "    if len(word) == 1 and word[0].token == star_token:  # frames predicted with star token\n",
    "        star_tokens = pred_ids[word[0].start:word[0].end]\n",
    "        words_map.append((processor.decode(star_tokens), 'deleted_word', word[0].score))\n",
    "        scores.append(word[0].score)\n",
    "        score_weights.append(1)\n",
    "        if debug:\n",
    "            # su.print_red(f'{dic_rev[word[0].token]} ({processor.decode(star_tokens)})', end='\\n')\n",
    "            debug_info += su.get_red(f'{dic_rev[word[0].token]} ({processor.decode(star_tokens)})')\n",
    "            \n",
    "    else:\n",
    "        for span in word:\n",
    "            if debug:\n",
    "                # su.print_green(f'{dic_rev[span.token]}', end='')\n",
    "                debug_info += su.get_green(f'{dic_rev[span.token]}')\n",
    "            # Weightage score - Consonants will have .7 weightage and vowel signs will have .3 weightage\n",
    "            token = processor.decode(span.token)\n",
    "            if token in matras:\n",
    "                scores.append(span.score * 0.3)\n",
    "                score_weights.append(0.3)\n",
    "            else:\n",
    "                scores.append(span.score * 0.7)\n",
    "                score_weights.append(0.7)\n",
    "            tokens.append(span.token)\n",
    "        words_map.append((processor.decode(tokens), 'word', sum(scores)/sum(score_weights)))\n",
    "        predicted_tokens = pred_ids[word[0].start:word[-1].end]\n",
    "\n",
    "        if debug and len(scores) > 0:\n",
    "            # su.print_blue(f' ({processor.decode(predicted_tokens)})', end='')\n",
    "            debug_info += su.get_blue(f' ({processor.decode(predicted_tokens)})')\n",
    "            diff = word[0].end - word[0].start\n",
    "            template = \" => {:<4} Token Scores: [{}] => {:.2f} / {:.1f} = {}\"\n",
    "            average_score = sum(scores) / sum(score_weights) if sum(score_weights) != 0 else 0  # Safe division\n",
    "            scores_2f = [f\"{score:.2f}\" for score in scores]\n",
    "            formatted_scores = \", \".join(f\"{su.get_green(score) if weight == 0.7 else su.get_blue(score)}\" for score, weight in zip(scores_2f, score_weights))\n",
    "            # print(template.format(\"\", formatted_scores, sum(scores), sum(score_weights), su.get_red(f\"{average_score:.2f}\")))\n",
    "            debug_info += template.format(\"\", formatted_scores, sum(scores), sum(score_weights), su.get_red(f\"{average_score:.2f}\"))\n",
    "\n",
    "    if scores:\n",
    "        word_scores.append((sum(scores)/sum(score_weights), processor.decode(tokens)))\n",
    "\n",
    "    return debug_info\n",
    "\n",
    "def is_correct(word_spans, text_tokens_shape, pred_ids, debug=False):\n",
    "    \"\"\"\n",
    "    Evaluates the accuracy of word spans extracted from predictions.\n",
    "    Determines if there are any deleted or incorrectly inserted words.\n",
    "    \n",
    "    Args:\n",
    "    word_spans : List[Tuple]\n",
    "        A list of word spans, each span being a tuple representing a word and its properties.\n",
    "    pred_ids : torch.Tensor\n",
    "        The predicted indices from the model, representing each audio frame's predicted token.\n",
    "    debug : bool, optional\n",
    "        Flag to enable detailed debug output. Default is False.\n",
    "\n",
    "    Returns:\n",
    "    dict\n",
    "        Dictionary containing information about deleted words, extra words, and whether an extra word should be removed.\n",
    "    \"\"\"\n",
    "    words_map = []\n",
    "    word_scores = []\n",
    "    star_token = len(dictionary) - 1  # star_token is the last token in the dictionary\n",
    "    deleted_words = []\n",
    "    debug_infos = []\n",
    "\n",
    "    # Process each word span for score and token analysis\n",
    "    for index, word in enumerate(word_spans):\n",
    "        di = process_word_scores(word, pred_ids, words_map, word_scores, star_token, debug)\n",
    "        debug_infos.append(di)\n",
    "\n",
    "    # Evaluate the predictions for contextual accuracy and potential errors\n",
    "    evaluate_predictions(words_map, deleted_words, replacements, matras, debug_infos, debug)\n",
    "\n",
    "    if debug:\n",
    "        print('\\n'.join(debug_infos))\n",
    "\n",
    "    # Determine the word with the minimum score and decide if it's an erroneously inserted word\n",
    "    if words_map:\n",
    "        min_word_score = min(words_map, key=lambda x: x[2])  # Find the word with the lowest probability score\n",
    "        threshold = 0.4  # Define a threshold for determining if a word is incorrectly inserted\n",
    "        remove_extra_word = min_word_score[2] < threshold\n",
    "        if debug:\n",
    "            print(f'Min Score word (Word Inserted): {min_word_score[0]} | score: {min_word_score[2]:.3f}')\n",
    "\n",
    "    else:\n",
    "        min_word_score = (\"\", 0)\n",
    "        remove_extra_word = False\n",
    "\n",
    "    return {\n",
    "        'has_deleted_word': deleted_words,\n",
    "        'remove_extra_word': remove_extra_word,\n",
    "        'min_prob_word': (min_word_score[0], min_word_score[2]),\n",
    "        'words_map': words_map,\n",
    "        'text_tokens_shape': text_tokens_shape\n",
    "    }\n",
    "\n",
    "audio = sample['audio']['array']\n",
    "test_audio = audio\n",
    "\n",
    "\n",
    "\n",
    "testing_cases = [5,7,9,12,19,20,23,26,27,28,29]\n",
    "# TODO: export this for documentation - may be push dataset to hub and store the indexes\n",
    "indic_voice_test_cases = [10,11,22,37,42,43,45]\n",
    "indic_voice_fast_testing_cases = [10577, 12333, 16355, 18426, 26449]\n",
    "shrutilipi_jai_test_cases = [10,26,32,33,34,40,41,42,47,49,54,58]\n",
    "shrutilipi_wrong_pred = [47,59,58]\n",
    "test_cases = [177277, 135468] # del words\n",
    "test_cases = [0, 6, 7, 15, 18, 21, 23, 25, 29, 35, 36, 41, 42, 43, 44, 46, 58, 59, 60, 64, 65, 69, 75, 77, 79, 81, 99, 104, 106, 107, 116, 120, 121, 122, 123, 136, 140, 141, 142, 144, 146, 147, 149, 157, 160, 162, 163, 166, 170, 171, 180, 183, 186, 188, 190, 191, 193, 198, 206, 211, 215, 222, 223, 225, 243, 246, 247, 249, 250, 251, 253, 254, 255, 257, 260, 262, 266, 271, 275, 276, 277, 278, 280, 281, 282, 285, 286, 289, 303, 304, 308, 310, 311, 315, 316, 319, 322, 324, 327, 332, 333, 335, 337, 338, 339, 340, 342, 343, 344, 345, 346, 348, 356, 357, 358, 359, 363, 365, 368, 369, 370, 371, 374, 376, 378, 381, 382, 383, 384, 385, 387, 388, 396,]\n",
    "ind = 0\n",
    "ind_end = ind + 5\n",
    "# for i in range(ind, ind_end):\n",
    "for i in test_cases:\n",
    "    s = ds[i]\n",
    "    test_text = f'{s[\"text\"]}'\n",
    "    norm_text = su.normalized_text(test_text, vocab_chars)\n",
    "    if norm_text == '':\n",
    "        print(f'The text contains digits or all characters not present in the vocab, which is not handled by the current implementation. Skipping this example.')\n",
    "        print(test_text)\n",
    "        continue\n",
    "\n",
    "    test_audio = s['audio']['array']\n",
    "    test_audio = np.concatenate([np.zeros(1425), test_audio, np.zeros(1425)]) # 85ms\n",
    "    norm_text = process_star_transcript(norm_text)\n",
    "    try:\n",
    "        result_v = is_correct(**get_word_spans(model_v, norm_text, test_audio), debug=True)\n",
    "        su.print_red('------------------------------------------------------------------------------------------------')\n",
    "        result_b = is_correct(**get_word_spans(model_b, norm_text, test_audio), debug=False)\n",
    "\n",
    "        res = result_v\n",
    "        del res['words_map']\n",
    "        print('Verbatim: ',res)\n",
    "        res = result_b\n",
    "        del res['words_map']\n",
    "        print('Base: ', res)\n",
    "    except Exception as e:\n",
    "        print('\\n\\n')\n",
    "        print(e)\n",
    "        raise ValueError('Alignment failed')\n",
    "        continue\n",
    "    # if len(numbered_indexes) > 0:\n",
    "    #     print(f'Numbered Indexes: {numbered_indexes}')\n",
    "    su.print_red(i)\n",
    "    print(norm_text)\n",
    "    ipd.display(ipd.Audio(test_audio, rate=SAMPLE_RATE))\n",
    "    print('\\n\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 957/307297 [02:20<11:21:51,  7.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAST OR EMTPY SPEECH: 955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1037/307297 [02:31<9:30:00,  8.95it/s] "
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for i in tqdm(range(len(ds))):\n",
    "    s = ds[i]\n",
    "    test_text = f'{s[\"text\"]}'\n",
    "    if 'source' not in s:\n",
    "        source = 'yt_stt'\n",
    "    else:\n",
    "        source = s['source']\n",
    "        if source == None:\n",
    "            source = 'indicsuperb'\n",
    "    norm_text = su.normalized_text(test_text, vocab_chars)\n",
    "    if norm_text == '':\n",
    "        # print(f'The text contains digits or all characters not present in the vocab, which is not handled by the current implementation. Skipping this example.')\n",
    "        # print(test_text)\n",
    "        results.append({'indicvoice_verbatim': None, 'all_ds': None, 'text': test_text, 'norm_text': norm_text, 'index': i, 'source': source, 'duration': s['duration']})\n",
    "        continue\n",
    "\n",
    "    test_audio = s['audio']['array']\n",
    "    test_audio = np.concatenate([np.zeros(1425), test_audio, np.zeros(1425)]) # (89.0625 * 2) ms\n",
    "    norm_text = process_star_transcript(norm_text)\n",
    "    try:\n",
    "        result_v = is_correct(**get_word_spans(model_v, norm_text, test_audio), debug=False)\n",
    "        result_b = is_correct(**get_word_spans(model_b, norm_text, test_audio), debug=False)\n",
    "    except Exception as e:\n",
    "        print(f'FAST OR EMTPY SPEECH: {i}')\n",
    "        result_v = {'has_deleted_word': [], 'remove_extra_word': True, 'min_prob_word': ('FAST OR EMTPY SPEECH', 0.0)}\n",
    "        result_b = {'has_deleted_word': [], 'remove_extra_word': True, 'min_prob_word': ('FAST OR EMTPY SPEECH', 0.0)}\n",
    "    results.append({'indicvoice_verbatim': result_v, 'all_ds': result_b, 'text': test_text, 'norm_text': norm_text, 'index': i, 'source': source, 'duration': s['duration']})\n",
    "\n",
    "print(len(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(alignment_save_result_file_name, 'wb') as f:\n",
    "    pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai4bharat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
